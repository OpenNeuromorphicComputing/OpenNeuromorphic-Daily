# ðŸ§  Open Neuromorphic - Daily ArXiv

**Automated Daily Update** | Last Run: 2026-02-02 08:41 UTC

Papers are automatically categorized by topic and sorted by date.

## ðŸ›  Hardware & Materials

### [Scalable Memory Sharing in Photonic Quantum Memristors for Reservoir Computing](http://arxiv.org/abs/2601.23044v1)
**2026-01-30** | *Chaehyeon Lim, Hyungchul Park, Beomjoon Chae et al.*

> Although photons are robust, room-temperature carriers well suited to quantum machine learning, the absence of photon-photon interactions hinder the realization of memory functionalities that are critical for capturing long-range context. Recently, measurement-based implementations of photonic quantum memristors (PQMRs) have enabled tunable non-Markovian responses. However, their memory remains confined to local elements, in contrast to biological or artificial networks where memory is shared across the system. Here, we propose a scalable PQMR network that enables measurement-based memory sharing. Each memristive node updates its internal state using the history of its own and neighbouring quantum states, thereby realizing distributed memory. By modelling each node as a photonic quantum memtransistor, we demonstrate pronounced enhancements in both classical and quantum hysteresis at the device level, as well as enhanced network-level quantum hysteresis. Implemented as a quantum reservoir, the architecture achieves improved Fashion-MNIST classification accuracy and confidence via increased data separability. Our approach paves the way toward high-capacity quantum machine learning using memristive devices compatible with linear-optical quantum computing.

### [Noise-Assisted Metastability: From LÃ©vy Flights to Memristors, Quantum Escape, and Josephson-based Axion Searches](http://arxiv.org/abs/2601.22635v1)
**2026-01-30** | *Claudio Guarcello, Alexander A. Dubkov, Davide Valenti et al.*

> Many-body and complex systems, both classical and quantum, often exhibit slow, nonlinear relaxation toward stationary states due to the presence of metastable configurations and environmental fluctuations. Nonlinear relaxation in a wide variety of natural systems proceeds through metastable states, which arise in condensed-matter physics as well as in fields ranging from cosmology and biology to high-energy physics. Moreover, noise-induced phenomena play a central role in shaping the dynamics of such systems far from equilibrium. This review develops a unifying perspective centered on noise-assisted stabilization and the statistical properties of metastable dynamics. We first discuss escape processes driven by LÃ©vy flights in smooth metastable potentials, emphasizing the emergence of nonmonotonic residence-time behavior. We then connect these concepts to stochastic resistive switching in memristive devices, where noise-induced effects can enhance stability and reproducibility. We further examine driven dissipative quantum bistability, showing how the interplay between external driving and system-environment coupling reshapes escape pathways and lifetimes. Finally, we outline how switching-time statistics in current-biased Josephson junctions can provide an experimentally accessible strategy for axion detection, based on an axion-induced resonant-activation signature.

### [Online unsupervised Hebbian learning in deep photonic neuromorphic networks](http://arxiv.org/abs/2601.22300v1)
**2026-01-29** | *Xi Li, Disha Biswas, Peng Zhou et al.*

> While software implementations of neural networks have driven significant advances in computation, the von Neumann architecture imposes fundamental limitations on speed and energy efficiency. Neuromorphic networks, with structures inspired by the brain's architecture, offer a compelling solution with the potential to approach the extreme energy efficiency of neurobiological systems. Photonic neuromorphic networks (PNNs) are particularly attractive because they leverage the inherent advantages of light, namely high parallelism, low latency, and exceptional energy efficiency. Previous PNN demonstrations have largely focused on device-level functionalities or system-level implementations reliant on supervised learning and inefficient optical-electrical-optical (OEO) conversions. Here, we introduce a purely photonic deep PNN architecture that enables online, unsupervised learning. We propose a local feedback mechanism operating entirely in the optical domain that implements a Hebbian learning rule using non-volatile phase-change material synapses. We experimentally demonstrate this approach on a non-trivial letter recognition task using a commercially available fiber-optic platform and achieve a 100 percent recognition rate, showcasing an all-optical solution for efficient, real-time information processing. This work unlocks the potential of photonic computing for complex artificial intelligence applications by enabling direct, high-throughput processing of optical information without intermediate OEO signal conversions.

### [Training slow silicon neurons to control extremely fast robots with spiking reinforcement learning](http://arxiv.org/abs/2601.21548v1)
**2026-01-29** | *Irene Ambrosini, Ingo Blakowski, Dmitrii Zendrikov et al.*

> Air hockey demands split-second decisions at high puck velocities, a challenge we address with a compact network of spiking neurons running on a mixed-signal analog/digital neuromorphic processor. By co-designing hardware and learning algorithms, we train the system to achieve successful puck interactions through reinforcement learning in a remarkably small number of trials. The network leverages fixed random connectivity to capture the task's temporal structure and adopts a local e-prop learning rule in the readout layer to exploit event-driven activity for fast and efficient learning. The result is real-time learning with a setup comprising a computer and the neuromorphic chip in-the-loop, enabling practical training of spiking neural networks for robotic autonomous systems. This work bridges neuroscience-inspired hardware with real-world robotic control, showing that brain-inspired approaches can tackle fast-paced interaction tasks while supporting always-on learning in intelligent machines.

### [FireFly-P: FPGA-Accelerated Spiking Neural Network Plasticity for Robust Adaptive Control](http://arxiv.org/abs/2601.21222v1)
**2026-01-29** | *Tenglong Li, Jindong Li, Guobin Shen et al.*

> Spiking Neural Networks (SNNs) offer a biologically plausible learning mechanism through synaptic plasticity, enabling unsupervised adaptation without the computational overhead of backpropagation. To harness this capability for robotics, this paper presents FireFly-P, an FPGA-based hardware accelerator that implements a novel plasticity algorithm for real-time adaptive control. By leveraging on-chip plasticity, our architecture enhances the network's generalization, ensuring robust performance in dynamic and unstructured environments. The hardware design achieves an end-to-end latency of just 8~$Î¼$s for both inference and plasticity updates, enabling rapid adaptation to unseen scenarios. Implemented on a tiny Cmod A7-35T FPGA, FireFly-P consumes only 0.713~W and $\sim$10K~LUTs, making it ideal for power- and resource-constrained embedded robotic platforms. This work demonstrates that hardware-accelerated SNN plasticity is a viable path toward enabling adaptive, low-latency, and energy-efficient control systems.

### [Si-Ga2O3/p-GaN epitaxial heterostructure based self-powered and visible-blind UV photodetectors with fast and electrically tuneable response time](http://arxiv.org/abs/2601.19492v1)
**2026-01-27** | *Ajoy Biswas, Amandeep Kaur, Bhabani Prasad Sahu et al.*

> n-Ga2O3/p-GaN heterojunction based photodetector devices are fabricated on Si-doped (-201) Î²-Ga2O3 epitaxial layers grown by pulsed laser deposition (PLD) technique on p-type c-GaN/sapphire templates. These devices demonstrate the ability to act as highly efficient self-powered visible blind UV-photodetectors with fast response time. It has been found that the optimum performance of the detector in terms of its responsivity, detectivity and response time could be achieved by adjusting the Si doping level and the thickness of the Ga2O3 layer. Our best performing device showing the peak responsivity and detectivity of 56.8 mA/W and 3*10^12 Jones, respectively, is achieved for 660 nm thick Ga2O3 layer with Si-concentration of 8*10^18 cm^-3. Moreover, as low as a few nW of optical signal can be sensed by the detector. The response time of the detector is found to be only a few tens of nanoseconds, which highlights their potential for application in ultrafast detection of UV light. These devices also exhibit a slower component of photoresponse with a timescale of a few tens of milliseconds. Interestingly, the time-scale of the slower response can be prolongated by several orders of magnitude through enhancing the applied reverse bias. Such an electrical tuneability of the response time is highly desirable for neuromorphic device applications.

### [RKKY-like interactions between two magnetic skyrmions](http://arxiv.org/abs/2601.17727v1)
**2026-01-25** | *Xuchong Hu, Huaiyang Yuan, Xiangrong Wang*

> Understanding skyrmion-skyrmion interactions is crucial for effectively manipulating the motion of multiple skyrmions in racetrack and logic devices. However, the fundamental nature and microscopic origins of these interactions remain poorly understood. In this study, we investigate skyrmion-skyrmion interactions in chiral magnetic films and reveal that they possess intrinsic, anisotropic, and oscillatory characteristics. Specifically, we demonstrate that the attractive and repulsive forces between skyrmions oscillate with a well-defined period, akin to the Ruderman-Kittel-Kasuya-Yosida (RKKY) coupling observed between two magnetic moments in metals. Our analysis uncovers the essential physics behind a previously unrecognized universal wavy tail in the skyrmion spin texture. Notably, the resulting RKKY-like interaction between skyrmions is universal for all tilted skyrmions, irrespective of whether the titled easy-axis is from an external field or a crystalline magnetic anisotropy. These findings introduce a novel physical principle for the design of skyrmion molecules or skyrmion superstructures, which hold significant potential for applications in skyrmion-based spintronics and neuromorphic computing.

### [Unsupervised sleep-like intra- and inter-layer plasticity categorizes and improves energy efficiency in a multilayer spiking network](http://arxiv.org/abs/2601.17523v1)
**2026-01-24** | *Leonardo Tonielli, Cosimo Lupo, Elena Pastorelli et al.*

> Sleep is thought to support memory consolidation and the recovery of optimal energetic regime by reorganizing synaptic connectivity, yet how plasticity across hierarchical brain circuits contributes to abstraction and energy efficiency remains unclear. Here we study a spiking multi-layer network alternating wake-like and deep-sleep-like states, with state-dependent dendritic integration and synaptic plasticity in a biologically inspired thalamo-cortical framework. During wakefulness, the model learns from few perceived examples, while during deep sleep it undergoes spontaneous replay driven by slow oscillations. Plasticity enabled not only within intra-layer connections, but also in inter-layer pathways, is critical for memory consolidation and energetic downshift. Compared to restricted plasticity, full inter-layer plasticity yields higher post-sleep visual classification accuracy and promotes the emergence of sharper class-specific associations. Furthermore, we introduce a biophysically grounded estimator of metabolic power expressing network energy consumption in ATP units, partitioned into baseline, synaptic maintenance, action potential, and transmission costs. We find that inter-layer plasticity in sleep leads to a larger reduction in firing rates, synaptic strength and synaptic activity, corresponding to a substantially larger decrease in power consumption. This work suggests promising elements to be integrated in neuromorphic/energy-efficient AI learning systems, supported by brain state-specific apical mechanisms.

### [Engineering the electronic structure of TiO$_2$ by transition metal doping: A First Principles DFT Study](http://arxiv.org/abs/2601.16735v1)
**2026-01-23** | *Vikash Mishra, Shashi Pandey, Swaroop Ganguly et al.*

> By means of first-principles density-functional theory (DFT) calculations, we perform a comparative analysis of the electronic and magnetic properties of transition metal-doped TiO$_2$. The electronic band gaps of Ti$_x$M$_{1-x}$O$_2$, where M represents 3d-transition metals such as Sc, V, Cr, Mn, Fe, Co, Ni, Cu, and Zn have been determined using the PBE functional within the generalized-gradient approximation (GGA) scheme, and also using the hybrid HSE06 functional. In the context of pure TiO$_2$, the partial density of states (PDOS) reveals that the electronic band gap emerges between the O-2p and Ti-3d orbitals. It is suggested that the Ti-3d ($t_{2g}$) states play a more prominent role in bonding compared to the Ti-3d ($e_g$) states. We performed DFT calculations to investigate the impact of doping with other 3d transition metal atoms, leading to the emergence of impurity states within the band gap. The hybridization between the oxygen 2p orbitals and the titanium 3d orbitals in TiO$_2$ is altered by the introduction of doping with 3d transition metals because of the change in the oxidation state of titanium, shifting from solely 4+ to a combination of 4+ and 3+ states. The calculation of spin-polarized density demonstrates the emergence of ferromagnetic properties, particularly in titanium dioxide doped with chromium (Cr), manganese (Mn), and iron (Fe) with large magnetic moments. Our work demonstrates the significant impact of doping transition metals on TiO$_2$, allowing for the precise manipulation of electrical and magnetic properties, and thus holds great potential for the development of spin-based memory devices with possible neuromorphic applications.

### [Current-induced magnetization control in dipolar-coupled nanomagnet pairs and artificial spin ice](http://arxiv.org/abs/2601.16633v1)
**2026-01-23** | *A. Pac, G. M. Macauley, J. A. Brock et al.*

> Exploiting current-induced spin-orbit torques (SOTs) to manipulate the magnetic state of dipolar-coupled nanomagnet systems with in-plane magnetic anisotropy, such as artificial spin ices, provides a route to local, electrically-programmable control of the magnetization, with relevance for applications including neuromorphic computing. Here, we demonstrate how the orientation of a nanomagnet relative to the direction of an applied electrical current impacts the threshold current density needed for all-electrical magnetization switching, and how dipolar coupling between the nanomagnets influences the switching of interacting pairs and ensembles of nanomagnets. Using a material system designed to generate SOTs in response to electrical currents, we find that the current required to switch the magnetization of isolated nanomagnets varies non-monotonically as the angle between the nanomagnet long axis and the current increases. In small artificial spin ice systems, we observe similar angular dependence of the switching current, which can be used to control the magnetization orientation of specific subsets of nanomagnets. These experimental results are supported by micromagnetic modeling, which illustrates how the various current induced torques can be exploited to control magnetization switching in nanomagnetic systems. These results establish SOT switching as a practical method for programmable manipulation of dipolar nanomagnetic systems.

### [Emerging Threats and Countermeasures in Neuromorphic Systems: A Survey](http://arxiv.org/abs/2601.16589v1)
**2026-01-23** | *Pablo Sorrentino, Stjepan Picek, Ihsen Alouani et al.*

> Neuromorphic computing mimics brain-inspired mechanisms through spiking neurons and energy-efficient processing, offering a pathway to efficient in-memory computing (IMC). However, these advancements raise critical security and privacy concerns. As the adoption of bio-inspired architectures and memristive devices increases, so does the urgency to assess the vulnerability of these emerging technologies to hardware and software attacks. Emerging architectures introduce new attack surfaces, particularly due to asynchronous, event-driven processing and stochastic device behavior. The integration of memristors into neuromorphic hardware and software implementations in spiking neural networks offers diverse possibilities for advanced computing architectures, including their role in security-aware applications. This survey systematically analyzes the security landscape of neuromorphic systems, covering attack methodologies, side-channel vulnerabilities, and countermeasures. We focus on both hardware and software concerns relevant to spiking neural networks (SNNs) and hardware primitives, such as Physical Unclonable Functions (PUFs) and True Random Number Generators (TRNGs) for cryptographic and secure computation applications. We approach this analysis from diverse perspectives, from attack methodologies to countermeasure strategies that integrate efficiency and protection in brain-inspired hardware. This review not only maps the current landscape of security threats but provides a foundation for developing secure and trustworthy neuromorphic architectures.

### [A Case for Hypergraphs to Model and Map SNNs on Neuromorphic Hardware](http://arxiv.org/abs/2601.16118v1)
**2026-01-22** | *Marco Ronzani, Cristina Silvano*

> Executing Spiking Neural Networks (SNNs) on neuromorphic hardware poses the problem of mapping neurons to cores. SNNs operate by propagating spikes between neurons that form a graph through synapses. Neuromorphic hardware mimics them through a network-on-chip, transmitting spikes, and a mesh of cores, each managing several neurons. Its operational cost is tied to spike movement and active cores. A mapping comprises two tasks: partitioning the SNN's graph to fit inside cores and placement of each partition on the hardware mesh. Both are NP-hard problems, and as SNNs and hardware scale towards billions of neurons, they become increasingly difficult to tackle effectively. In this work, we propose to raise the abstraction of SNNs from graphs to hypergraphs, redesigning mapping techniques accordingly. The resulting model faithfully captures the replication of spikes inside cores by exposing the notion of hyperedge co-membership between neurons. We further show that the overlap and locality of hyperedges strongly correlate with high-quality mappings, making these properties instrumental in devising mapping algorithms. By exploiting them directly, grouping neurons through shared hyperedges, communication traffic and hardware resource usage can be reduced be yond what just contracting individual connections attains. To substantiate this insight, we consider several partitioning and placement algorithms, some newly devised, others adapted from literature, and compare them over progressively larger and bio-plausible SNNs. Our results show that hypergraph based techniques can achieve better mappings than the state-of-the-art at several execution time regimes. Based on these observations, we identify a promising selection of algorithms to achieve effective mappings at any scale.

### [CVD grown bilayer MoS2 based artificial optoelectronic synapses for arithmetic computing and image recognition applications](http://arxiv.org/abs/2601.15917v1)
**2026-01-22** | *Umakanta Patra, Subhrajit Sikdar, Roshan Padhan et al.*

> Demand for lower computing power has rapidly increased. In this context, brain-inspired neuromorphic computing, which integrate data storage and processing, has attracted significant attention. Here, our study reveals that field effect transistors fabricated on chemical vapor deposited bilayer (2L) MoS2 films can mimic the functions of biological synapse. These devices demonstrate high level of pair pulse facilitation (PPF), short term to long term memory (STM-to-LTM) transition as well as learning-forgetting-relearning properties. Effect of light intensity, pulse number, pulse width and photon energy on the STM-to-LTM transition is studied. It has been found that the rate of depression of the memory state can be controlled using the gate bias. Electrical and optical energy consumptions per synaptic event are estimated to be as low as 280 fJ and 20 nJ, respectively. Furthermore, photocurrent in these devices is observed to increase linearly with the number of the excitation pulses. This property has been exploited to demonstrate different arithmetic operations by the device. Moreover, these devices show great potential for image recognition. Artificial neural network simulation has returned an image recognition accuracy of ~85%. All these findings show a great prospect of 2L-MoS2 for developing low power, transparent and flexible neuromorphic devices.

---

## ðŸ§  Algorithms & Theory

### [Matterhorn: Efficient Analog Sparse Spiking Transformer Architecture with Masked Time-To-First-Spike Encoding](http://arxiv.org/abs/2601.22876v1)
**2026-01-30** | *Zhanglu Yan, Kaiwen Tang, Zixuan Zhu et al.*

> Spiking neural networks (SNNs) have emerged as a promising candidate for energy-efficient LLM inference. However, current energy evaluations for SNNs primarily focus on counting accumulate operations, and fail to account for real-world hardware costs such as data movement, which can consume nearly 80% of the total energy. In this paper, we propose Matterhorn, a spiking transformer that integrates a novel masked time-to-first-spike (M-TTFS) encoding method to reduce spike movement and a memristive synapse unit (MSU) to eliminate weight access overhead. M-TTFS employs a masking strategy that reassigns the zero-energy silent state (a spike train of all 0s) to the most frequent membrane potential rather than the lowest. This aligns the coding scheme with the data distribution, minimizing spike movement energy without information loss. We further propose a `dead zone' strategy that maximizes sparsity by mapping all values within a given range to the silent state. At the hardware level, the MSU utilizes compute-in-memory (CIM) technology to perform analog integration directly within memory, effectively removing weight access costs. On the GLUE benchmark, Matterhorn establishes a new state-of-the-art, surpassing existing SNNs by 1.42% in average accuracy while delivering a 2.31 times improvement in energy efficiency.

### [Fire on Motion: Optimizing Video Pass-bands for Efficient Spiking Action Recognition](http://arxiv.org/abs/2601.22675v1)
**2026-01-30** | *Shuhan Ye, Yuanbin Qian, Yi Yu et al.*

> Spiking neural networks (SNNs) have gained traction in vision due to their energy efficiency, bio-plausibility, and inherent temporal processing. Yet, despite this temporal capacity, most progress concentrates on static image benchmarks, and SNNs still underperform on dynamic video tasks compared to artificial neural networks (ANNs). In this work, we diagnose a fundamental pass-band mismatch: Standard spiking dynamics behave as a temporal low pass that emphasizes static content while attenuating motion bearing bands, where task relevant information concentrates in dynamic tasks. This phenomenon explains why SNNs can approach ANNs on static tasks yet fall behind on tasks that demand richer temporal understanding.To remedy this, we propose the Pass-Bands Optimizer (PBO), a plug-and-play module that optimizes the temporal pass-band toward task-relevant motion bands. PBO introduces only two learnable parameters, and a lightweight consistency constraint that preserves semantics and boundaries, incurring negligible computational overhead and requires no architectural changes. PBO deliberately suppresses static components that contribute little to discrimination, effectively high passing the stream so that spiking activity concentrates on motion bearing content. On UCF101, PBO yields over ten percentage points improvement. On more complex multi-modal action recognition and weakly supervised video anomaly detection, PBO delivers consistent and significant gains, offering a new perspective for SNN based video processing and understanding.

### [General Self-Prediction Enhancement for Spiking Neurons](http://arxiv.org/abs/2601.21823v1)
**2026-01-29** | *Zihan Huang, Zijie Xu, Yihan Huang et al.*

> Spiking Neural Networks (SNNs) are highly energy-efficient due to event-driven, sparse computation, but their training is challenged by spike non-differentiability and trade-offs among performance, efficiency, and biological plausibility. Crucially, mainstream SNNs ignore predictive coding, a core cortical mechanism where the brain predicts inputs and encodes errors for efficient perception. Inspired by this, we propose a self-prediction enhanced spiking neuron method that generates an internal prediction current from its input-output history to modulate membrane potential. This design offers dual advantages, it creates a continuous gradient path that alleviates vanishing gradients and boosts training stability and accuracy, while also aligning with biological principles, which resembles distal dendritic modulation and error-driven synaptic plasticity. Experiments show consistent performance gains across diverse architectures, neuron types, time steps, and tasks demonstrating broad applicability for enhancing SNNs.

### [Error Amplification Limits ANN-to-SNN Conversion in Continuous Control](http://arxiv.org/abs/2601.21778v1)
**2026-01-29** | *Zijie Xu, Zihan Huang, Yiting Dong et al.*

> Spiking Neural Networks (SNNs) can achieve competitive performance by converting already existing well-trained Artificial Neural Networks (ANNs), avoiding further costly training. This property is particularly attractive in Reinforcement Learning (RL), where training through environment interaction is expensive and potentially unsafe. However, existing conversion methods perform poorly in continuous control, where suitable baselines are largely absent. We identify error amplification as the key cause: small action approximation errors become temporally correlated across decision steps, inducing cumulative state distribution shift and severe performance degradation. To address this issue, we propose Cross-Step Residual Potential Initialization (CRPI), a lightweight training-free mechanism that carries over residual membrane potentials across decision steps to suppress temporally correlated errors. Experiments on continuous control benchmarks with both vector and visual observations demonstrate that CRPI can be integrated into existing conversion pipelines and substantially recovers lost performance. Our results highlight continuous control as a critical and challenging benchmark for ANN-to-SNN conversion, where small errors can be strongly amplified and impact performance.

### [Signal-Adaptive Trust Regions for Gradient-Free Optimization of Recurrent Spiking Neural Networks](http://arxiv.org/abs/2601.21572v1)
**2026-01-29** | *Jinhao Li, Yuhao Sun, Zhiyuan Ma et al.*

> Recurrent spiking neural networks (RSNNs) are a promising substrate for energy-efficient control policies, but training them for high-dimensional, long-horizon reinforcement learning remains challenging. Population-based, gradient-free optimization circumvents backpropagation through non-differentiable spike dynamics by estimating gradients. However, with finite populations, high variance of these estimates can induce harmful and overly aggressive update steps. Inspired by trust-region methods in reinforcement learning that constrain policy updates in distribution space, we propose \textbf{Signal-Adaptive Trust Regions (SATR)}, a distributional update rule that constrains relative change by bounding KL divergence normalized by an estimated signal energy. SATR automatically expands the trust region under strong signals and contracts it when updates are noise-dominated. We instantiate SATR for Bernoulli connectivity distributions, which have shown strong empirical performance for RSNN optimization. Across a suite of high-dimensional continuous-control benchmarks, SATR improves stability under limited populations and reaches competitive returns against strong baselines including PPO-LSTM. In addition, to make SATR practical at scale, we introduce a bitset implementation for binary spiking and binary weights, substantially reducing wall-clock training time and enabling fast RSNN policy search.

### [MAR: Efficient Large Language Models via Module-aware Architecture Refinement](http://arxiv.org/abs/2601.21503v1)
**2026-01-29** | *Junhong Cai, Guiqin Wang, Kejie Zhao et al.*

> Large Language Models (LLMs) excel across diverse domains but suffer from high energy costs due to quadratic attention and dense Feed-Forward Network (FFN) operations. To address these issues, we propose Module-aware Architecture Refinement (MAR), a two-stage framework that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce FFN costs. In addition, to mitigate low information density and temporal mismatch in integrating Spiking Neural Networks (SNNs) with SSMs, we design the Adaptive Ternary Multi-step Neuron (ATMN) and the Spike-aware Bidirectional Distillation Strategy (SBDS). Extensive experiments demonstrate that MAR effectively restores the performance of its dense counterpart under constrained resources while substantially reducing inference energy consumption. Furthermore, it outperforms efficient models of comparable or even larger scale, underscoring its potential for building efficient and practical LLMs.

### [BrainFuse: a unified infrastructure integrating realistic biological modeling and core AI methodology](http://arxiv.org/abs/2601.21407v1)
**2026-01-29** | *Baiyu Chen, Yujie Wu, Siyuan Xu et al.*

> Neuroscience and artificial intelligence represent distinct yet complementary pathways to general intelligence. However, amid the ongoing boom in AI research and applications, the translational synergy between these two fields has grown increasingly elusive-hampered by a widening infrastructural incompatibility: modern AI frameworks lack native support for biophysical realism, while neural simulation tools are poorly suited for gradient-based optimization and neuromorphic hardware deployment. To bridge this gap, we introduce BrainFuse, a unified infrastructure that provides comprehensive support for biophysical neural simulation and gradient-based learning. By addressing algorithmic, computational, and deployment challenges, BrainFuse exhibits three core capabilities: (1) algorithmic integration of detailed neuronal dynamics into a differentiable learning framework; (2) system-level optimization that accelerates customizable ion-channel dynamics by up to 3,000x on GPUs; and (3) scalable computation with highly compatible pipelines for neuromorphic hardware deployment. We demonstrate this full-stack design through both AI and neuroscience tasks, from foundational neuron simulation and functional cylinder modeling to real-world deployment and application scenarios. For neuroscience, BrainFuse supports multiscale biological modeling, enabling the deployment of approximately 38,000 Hodgkin-Huxley neurons with 100 million synapses on a single neuromorphic chip while consuming as low as 1.98 W. For AI, BrainFuse facilitates the synergistic application of realistic biological neuron models, demonstrating enhanced robustness to input noise and improved temporal processing endowed by complex HH dynamics. BrainFuse therefore serves as a foundational engine to facilitate cross-disciplinary research and accelerate the development of next-generation bio-inspired intelligent systems.

### [NEXUS: Bit-Exact ANN-to-SNN Equivalence via Neuromorphic Gate Circuits with Surrogate-Free Training](http://arxiv.org/abs/2601.21279v2)
**2026-01-29** | *Zhengzheng Tang*

> Spiking Neural Networks (SNNs) promise energy-efficient computing through event-driven sparsity, yet all existing approaches sacrifice accuracy by approximating continuous values with discrete spikes. We propose NEXUS, a framework that achieves bit-exact ANN-to-SNN equivalence -- not approximate, but mathematically identical outputs. Our key insight is constructing all arithmetic operations, both linear and nonlinear, from pure IF neuron logic gates that implement IEEE-754 compliant floating-point arithmetic. Through spatial bit encoding (zero encoding error by construction), hierarchical neuromorphic gate circuits (from basic logic gates to complete transformer layers), and surrogate-free STE training (exact identity mapping rather than heuristic approximation), NEXUS produces outputs identical to standard ANNs up to machine precision. Experiments on models up to LLaMA-2 70B demonstrate identical task accuracy (0.00% degradation) with mean ULP error of only 6.19, while achieving 27-168,000$\times$ energy reduction on neuromorphic hardware. Crucially, spatial bit encoding's single-timestep design renders the framework inherently immune to membrane potential leakage (100% accuracy across all decay factors $Î²\in[0.1,1.0]$), while tolerating synaptic noise up to $Ïƒ=0.2$ with >98% gate-level accuracy.

### [TEFormer: Structured Bidirectional Temporal Enhancement Modeling in Spiking Transformers](http://arxiv.org/abs/2601.18274v1)
**2026-01-26** | *Sicheng Shen, Mingyang Lv, Bing Han et al.*

> In recent years, Spiking Neural Networks (SNNs) have achieved remarkable progress, with Spiking Transformers emerging as a promising architecture for energy-efficient sequence modeling. However, existing Spiking Transformers still lack a principled mechanism for effective temporal fusion, limiting their ability to fully exploit spatiotemporal dependencies. Inspired by feedforward-feedback modulation in the human visual pathway, we propose TEFormer, the first Spiking Transformer framework that achieves bidirectional temporal fusion by decoupling temporal modeling across its core components. Specifically, TEFormer employs a lightweight and hyperparameter-free forward temporal fusion mechanism in the attention module, enabling fully parallel computation, while incorporating a backward gated recurrent structure in the MLP to aggregate temporal information in reverse order and reinforce temporal consistency. Extensive experiments across a wide range of benchmarks demonstrate that TEFormer consistently and significantly outperforms strong SNN and Spiking Transformer baselines under diverse datasets. Moreover, through the first systematic evaluation of Spiking Transformers under different neural encoding schemes, we show that the performance gains of TEFormer remain stable across encoding choices, indicating that the improved temporal modeling directly translates into reliable accuracy improvements across varied spiking representations. These results collectively establish TEFormer as an effective and general framework for temporal modeling in Spiking Transformers.

### [Laser interferometry as a robust neuromorphic platform for machine learning](http://arxiv.org/abs/2601.18047v2)
**2026-01-26** | *Amanuel Anteneh, Kyungeun Kim, J. M. Schwarz et al.*

> We present a method for implementing an optical neural network using only linear optical resources, namely field displacement and interferometry applied to coherent states of light. The nonlinearity required for learning in a neural network is realized via an encoding of the input into phase shifts allowing for far more straightforward experimental implementation compared to previous proposals for, and demonstrations of, $\textit{in situ}$ inference. Beyond $\textit{in situ}$ inference, the method enables $\textit{in situ}$ training by utilizing established techniques like parameter shift rules or physical backpropagation to extract gradients directly from measurements of the linear optical circuit. We also investigate the effect of photon losses and find the model to be very resilient to these.

### [Reliable Brain Tumor Segmentation Based on Spiking Neural Networks with Efficient Training](http://arxiv.org/abs/2601.16652v1)
**2026-01-23** | *Aurora Pia Ghiardelli, Guangzhi Tang, Tao Sun*

> We propose a reliable and energy-efficient framework for 3D brain tumor segmentation using spiking neural networks (SNNs). A multi-view ensemble of sagittal, coronal, and axial SNN models provides voxel-wise uncertainty estimation and enhances segmentation robustness. To address the high computational cost in training SNN models for semantic image segmentation, we employ Forward Propagation Through Time (FPTT), which maintains temporal learning efficiency with significantly reduced computational cost. Experiments on the Multimodal Brain Tumor Segmentation Challenges (BraTS 2017 and BraTS 2023) demonstrate competitive accuracy, well-calibrated uncertainty, and an 87% reduction in FLOPs, underscoring the potential of SNNs for reliable, low-power medical IoT and Point-of-Care systems.

### [Spiking Neural Networks for Communication Systems: Encoding Schemes, Learning Algorithms, and Equalization~Techniques](http://arxiv.org/abs/2601.16550v1)
**2026-01-23** | *Eike-Manuel Edelmann*

> Machine learning with artificial neural networks (ANNs), provides solutions for the growing complexity of modern communication systems. This complexity, however, increases power consumption, making the systems energy-intensive. Spiking neural networks (SNNs) represent a novel generation of neural networks inspired by the highly efficient human brain. By emulating its event-driven and energy-efficient mechanisms, SNNs enable low-power, real-time signal processing. They differ from ANNs in two key ways: they exhibit inherent temporal dynamics and process and transmit information as short binary signals called spikes. Despite their promise, major challenges remain, e.g., identifying optimal learning rules and effective neural encoding. This thesis investigates the design of SNN-based receivers for nonlinear time-invariant frequency-selective channels. Backpropagation through time with surrogate gradients is identified as a promising update rule and the novel quantization encoding (QE) as promising neural encoding. Given the model of the intensity modulation with direct detection link, we compare two different receiver architectures based on equalization performance and spike count. Using decision feedback and QE achieves both strong performance and low spike counts. Notably, SNN-based receivers significantly outperform ANN-based counterparts. We furthermore introduce policy gradient-based update (PGU), an reinforcement learning-based update algorithm that requires no backpropagation. Using PGU, encoding parameters are optimized, drastically reducing runtime, complexity, and spikes per inference while maintaining performance. This thesis contributes a successful design and optimization framework for SNN-based receivers. By addressing key challenges in SNN optimization, it facilitates future advances in the design and deployment of energy-efficient SNN receivers.

---

## ðŸ‘ï¸ Applications & Sensing

### [Dependence of Equilibrium Propagation Training Success on Network Architecture](http://arxiv.org/abs/2601.21945v1)
**2026-01-29** | *Qingshan Wang, Clara C. Wanjura, Florian Marquardt*

> The rapid rise of artificial intelligence has led to an unsustainable growth in energy consumption. This has motivated progress in neuromorphic computing and physics-based training of learning machines as alternatives to digital neural networks. Many theoretical studies focus on simple architectures like all-to-all or densely connected layered networks. However, these may be challenging to realize experimentally, e.g. due to connectivity constraints. In this work, we investigate the performance of the widespread physics-based training method of equilibrium propagation for more realistic architectural choices, specifically, locally connected lattices. We train an XY model and explore the influence of architecture on various benchmark tasks, tracking the evolution of spatially distributed responses and couplings during training. Our results show that sparse networks with only local connections can achieve performance comparable to dense networks. Our findings provide guidelines for further scaling up architectures based on equilibrium propagation in realistic settings.

### [NeuroAI and Beyond](http://arxiv.org/abs/2601.19955v1)
**2026-01-27** | *Jean-Marc Fellous, Gert Cauwenberghs, Cornelia FermÃ¼ller et al.*

> Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.

### [Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing](http://arxiv.org/abs/2601.19079v1)
**2026-01-27** | *Naqash Afzal, Niklas Funk, Erik Helmut et al.*

> Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.

### [Uncooled Poisson Bolometer for High-Speed Event-Based Long-wave Thermal Imaging](http://arxiv.org/abs/2601.18583v1)
**2026-01-26** | *Mohamed A. Mousa, Leif Bauer, Utkarsh Singh et al.*

> Event-based vision provides high-speed, energy-efficient sensing for applications such as autonomous navigation and motion tracking. However, implementing this technology in the long-wave infrared remains a significant challenge. Traditional infrared sensors are hindered by slow thermal response times or the heavy power requirements of cryogenic cooling. Here, we introduce the first event-based infrared detector operating in a Poisson-counting regime. This is realized with a spintronic Poisson bolometer capable of broadband detection from 0.8-14$Î¼\text{m}$. In this regime, infrared signals are detected through statistically resolvable changes in stochastic switching events. This approach enables room-temperature operation with high timing resolution. Our device achieves a maximum event rate of 1,250 Hz, surpassing the temporal resolution of conventional uncooled microbolometers by a factor of 4. Power consumption is kept low at 0.2$Î¼$W per pixel. This work establishes an operating principle for infrared sensing and demonstrates a pathway toward high-speed, energy-efficient, event-driven thermal imaging.

### [NeuroManip: Prosthetic Hand Manipulation System Based on EMG and Eye Tracking Powered by the Neuromorphic Processor AltAi](http://arxiv.org/abs/2601.17991v1)
**2026-01-25** | *Roman Akinshin, Elizaveta Lopatina, Kirill Bogatikov et al.*

> This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.

---

