# ðŸ§  Open Neuromorphic - Daily ArXiv

**Automated Daily Update** | Last Run: 2026-01-10 08:26 UTC

Papers are automatically categorized by topic and sorted by date.

## ðŸ›  Hardware & Materials

### [Local Multimodal Dynamics in Mixed Ionic-Electronic Conductors and Their Fingerprints in Organic Electrochemical Transistor Operation](http://arxiv.org/abs/2601.05179v1)
**2026-01-08** | *Shubham Tanwar, Han-Yan Wu, Chi-Yuan Yang et al.*

> Mixed ionic-electronic conductors host tightly coupled interactions among mobile ions, electronic charges, and the polymer matrix, giving rise to complex multimodal responses spanning electrical, mechanical, and morphological transformations. These materials underpin organic electrochemical transistors (OECTs), which translate such interactions into low-voltage signal amplification and sensing for applications in bioelectronics, neuromorphic computing, and memory. Despite their central role, OECT current-voltage transfer characteristics are often treated phenomenologically, as both the local multimodal dynamics and their connection to global device response remain unresolved. Here, we reveal that the transfer curve encodes a cascade of spatially localized electrochemical transitions, each associated with distinct changes in conductivity, stiffness, and morphology, fundamentally redefining it as a spatially resolved fingerprint of device's internal state. Using automated operando multimodal in-liquid scanning dielectric microscopy, we directly map these dynamics and identify region-specific electrochemical thresholds governing the interplay between source, channel, and drain. We found that the local tip-sample electrostatic force serves as a remarkable mechanistic observable of coupled multimodal dynamics in mixed conductors. A physically grounded model links it to general material, interfacial, and geometric parameters, enabling mechanistic interpretation and predictive insights. Our work provides a new framework for probing and understanding mixed conduction in ion-electron coupled systems.

### [K-ion intercalation memristors in prussian blue analogs revealed by C-AFM for Non-Volatile memory and Neuromorphic Computing](http://arxiv.org/abs/2601.04724v1)
**2026-01-08** | *L. B. Avila, O. Leuve, M. Pohlitz et al.*

> Here, we demonstrate K-ion intercalation-mediated resistive switching in Prussian blue analogs (PBAs), a mechanism widely exploited in potassium batteries but not previously resolved at the nanoscale for memristive operation. Using C-AFM, we directly visualize and electrically control this intercalation process within sub-100-nm volumes, revealing reversible, localized conductance modulation driven by K-ion intercalation and Fe2+/Fe3+ redox reconfiguration. This nanoscale operability highlights the exceptional potential of PBAs for high-scalable and low-dimension memristor-based devices integration. Due to their modular composition, PBAs constitute a chemically rich, earth-abundant materials platform whose electronic and ionic properties can be precisely tuned for specific device functions. K-ion intercalation PBA-based memristor devices, with their singlestep, aqueous, and room-temperature fabrication, enable low-cost, large-scale processing compatible with CMOS, without any additional post-fabrication processing. Our findings establish PBAs as a new class of intercalation memristors with scalable nanoscale switching and exceptional materials versatility, toward highly integrated neuromorphic and non-volatile memory technologies. This work provides the first demonstration of intercalation-driven resistive switching under ultrafast voltage sweeps, with PW operating up to 200 V/s and PB up to 50 V/s. This unprecedented speed establishes PBAs as a distinct, high-rate class of K-ion intercalation memristors suitable for fast, high-density neuromorphic and memory applications.

### [Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing](http://arxiv.org/abs/2601.04476v1)
**2026-01-08** | *Chuanzhen Wang, Leo Zhang, Eric Liu*

> Recent hardware acceleration advances have enabled powerful specialized accelerators for finite element computations, spiking neural network inference, and sparse tensor operations. However, existing approaches face fundamental limitations: (1) finite element methods lack comprehensive rounding error analysis for reduced-precision implementations and use fixed precision assignment strategies that cannot adapt to varying numerical conditioning; (2) spiking neural network accelerators cannot handle non-spike operations and suffer from bit-width escalation as network depth increases; and (3) FPGA tensor accelerators optimize only for dense computations while requiring manual configuration for each sparsity pattern. To address these challenges, we introduce \textbf{Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing}, a novel framework that integrates three enhanced modules with memory-guided adaptation for efficient mixed-workload processing on unified platforms. Our approach employs memory-guided precision selection to overcome fixed precision limitations, integrates experience-driven bit-width management and dynamic parallelism adaptation for enhanced spiking neural network acceleration, and introduces curriculum learning for automatic sparsity pattern discovery. Extensive experiments on FEniCS, COMSOL, ANSYS benchmarks, MNIST, CIFAR-10, CIFAR-100, DVS-Gesture datasets, and COCO 2017 demonstrate 2.8\% improvement in numerical accuracy, 47\% throughput increase, 34\% energy reduction, and 45-65\% throughput improvement compared to specialized accelerators. Our work enables unified processing of finite element methods, spiking neural networks, and sparse computations on a single platform while eliminating data transfer overhead between separate units.

### [A Quantifiable Information-Processing Hierarchy Provides a Necessary Condition for Detecting Agency](http://arxiv.org/abs/2601.03498v1)
**2026-01-07** | *Brett J. Kagan, Valentina Baccetti, Brian D. Earp et al.*

> As intelligent systems are developed across diverse substrates - from machine learning models and neuromorphic hardware to in vitro neural cultures - understanding what gives a system agency has become increasingly important. Existing definitions, however, tend to rely on top-down descriptions that are difficult to quantify. We propose a bottom-up framework grounded in a system's information-processing order: the extent to which its transformation of input evolves over time. We identify three orders of information processing. Class I systems are reactive and memoryless, mapping inputs directly to outputs. Class II systems incorporate internal states that provide memory but follow fixed transformation rules. Class III systems are adaptive; their transformation rules themselves change as a function of prior activity. While not sufficient on their own, these dynamics represent necessary informational conditions for genuine agency. This hierarchy offers a measurable, substrate-independent way to identify the informational precursors of agency. We illustrate the framework with neurophysiological and computational examples, including thermostats and receptor-like memristors, and discuss its implications for the ethical and functional evaluation of systems that may exhibit agency.

### [Integrated magnonic chip using cascaded logic](http://arxiv.org/abs/2601.02644v1)
**2026-01-06** | *Mengying Guo, Xudong Jing, KristÃ½na DavÃ­dkovÃ¡ et al.*

> The transistor transformed not only electronics but everyday life, and the integrated circuit - now simply the "chip" - made computation scalable and ubiquitous. Magnonics has long promised a parallel path to low-energy information processing by using spin waves instead of charge. Progress, however, has been limited by two fundamental obstacles: intrinsic attenuation of spin waves and the requirement for precisely normalised output intensity and input phase to ensure reliable logic operation - conditions that are difficult to maintain in large-scale circuits owing to inevitable imperfections. Here, we report an integrated magnonic circuit that overcomes both limitations through engineered nonlinearity in nanoscale yttrium iron garnet waveguides. Nonlinear self-adjustment of the spin wave phase renders logic operation insensitive to the relative phases of the inputs, while a deeply nonlinear, threshold-activated self-normalised excitation restores and standardises the output intensity. Using space-resolved micro-focused Brillouin light scattering, we demonstrate reconfigurable AND, OR and three-input majority gates and realise deterministic cascading across sequential stages, establishing a scalable on-chip logic primitive. The architecture operates with gigahertz frequencies, supports dynamic threshold control for functional reconfiguration, and is compatible with scalable integration, making it attractive for adaptive and neuromorphic computing. By resolving phase-independent operation and signal restoration at the level of device physics, this work advances magnonics from isolated proof-of-concept devices towards integrated magnonic chips that can complement advanced CMOS in energy-constrained computing tasks.

### [Sparsity-Aware Streaming SNN Accelerator with Output-Channel Dataflow for Automatic Modulation Classification](http://arxiv.org/abs/2601.02613v1)
**2026-01-06** | *Kuilian Yang, Li Zhang, Ahmed M. Eltawil et al.*

> The rapid advancement of wireless communication technologies, including 5G, emerging 6G networks, and the large-scale deployment of the Internet of Things (IoT), has intensified the need for efficient spectrum utilization. Automatic modulation classification (AMC) plays a vital role in cognitive radio systems by enabling real-time identification of modulation schemes for dynamic spectrum access and interference mitigation. While deep neural networks (DNNs) offer high classification accuracy, their computational and energy demands pose challenges for real-time edge deployment. Spiking neural networks (SNNs), with their event-driven nature, offer inherent energy efficiency, but achieving both high throughput and low power under constrained hardware resources remains challenging. This work proposes a sparsity-aware SNN streaming accelerator optimized for AMC tasks. Unlike traditional systolic arrays that exploit sparsity but suffer from low throughput, or streaming architectures that achieve high throughput but cannot fully utilize input and weight sparsity, our design integrates both advantages. By leveraging the fixed nature of kernels during inference, we apply the gated one-to-all product (GOAP) algorithm to compute only on non-zero input-weight intersections. Extra or empty iterations are precomputed and embedded into the inference dataflow, eliminating dynamic data fetches and enabling fully pipelined, control-free inter-layer execution. Implemented on an FPGA, our sparsity-aware output-channel dataflow streaming (SAOCDS) accelerator achieves 23.5 MS/s (approximately double the baseline throughput) on the RadioML 2016 dataset, while reducing dynamic power and maintaining comparable classification accuracy. These results demonstrate strong potential for real-time, low-power deployment in edge cognitive radio systems.

### [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](http://arxiv.org/abs/2601.02253v1)
**2026-01-05** | *Emrah Mete, Emin Erkan Korkmaz*

> The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

### [Toward Thermodynamic Reservoir Computing: Exploring SHA-256 ASICs as Potential Physical Substrates](http://arxiv.org/abs/2601.01916v1)
**2026-01-05** | *Francisco Angulo de Lafuente, Vladimir Veselov, Richard Goodman*

> We propose a theoretical framework--Holographic Reservoir Computing (HRC)--which hypothesizes that the thermodynamic noise and timing dynamics in voltage-stressed Bitcoin mining ASICs (BM1366) could potentially serve as a physical reservoir computing substrate. We present the CHIMERA (Conscious Hybrid Intelligence via Miner-Embedded Resonance Architecture) system architecture, which treats the SHA-256 hashing pipeline not as an entropy source, but as a deterministic diffusion operator whose timing characteristics under controlled voltage and frequency conditions may exhibit computationally useful dynamics. We report preliminary observations of non-Poissonian variability in inter-arrival time statistics during edge-of-stability operation, which we term the "Silicon Heartbeat" hypothesis. Theoretical analysis based on Hierarchical Number System (HNS) representations suggests that such architectures could achieve O(log n) energy scaling compared to traditional von Neumann O(2^n) dependencies. However, we emphasize that these are theoretical projections requiring experimental validation. We present the implemented measurement infrastructure, acknowledge current limitations, and outline the experimental program necessary to confirm or refute these hypotheses. This work contributes to the emerging field of thermodynamic computing by proposing a novel approach to repurposing obsolete cryptographic hardware for neuromorphic applications.

### [Image Synthesis Using Spintronic Deep Convolutional Generative Adversarial Network](http://arxiv.org/abs/2601.01441v1)
**2026-01-04** | *Saumya Gupta, Abhinandan, Venkatesh vadde et al.*

> The computational requirements of generative adversarial networks (GANs) exceed the limit of conventional Von Neumann architectures, necessitating energy efficient alternatives such as neuromorphic spintronics. This work presents a hybrid CMOS-spintronic deep convolutional generative adversarial network (DCGAN) architecture for synthetic image generation. The proposed generative vision model approach follows the standard framework, leveraging generator and discriminators adversarial training with our designed spintronics hardware for deconvolution, convolution, and activation layers of the DCGAN architecture. To enable hardware aware spintronic implementation, the generator's deconvolution layers are restructured as zero padded convolution, allowing seamless integration with a 6-bit skyrmion based synapse in a crossbar, without compromising training performance. Nonlinear activation functions are implemented using a hybrid CMOS domain wall based Rectified linear unit (ReLU) and Leaky ReLU units. Our proposed tunable Leaky ReLU employs domain wall position coded, continuous resistance states and a piecewise uniaxial parabolic anisotropy profile with a parallel MTJ readout, exhibiting energy consumption of 0.192 pJ. Our spintronic DCGAN model demonstrates adaptability across both grayscale and colored datasets, achieving Fr'echet Inception Distances (FID) of 27.5 for the Fashion MNIST and 45.4 for Anime Face datasets, with testing energy (training energy) of 4.9 nJ (14.97~nJ/image) and 24.72 nJ (74.7 nJ/image).

### [Analog Weight Update Rule in Ferroelectric Hafnia, using pico-Joule Programming Pulses](http://arxiv.org/abs/2601.01186v1)
**2026-01-03** | *Alexandre Baigol, Nikhil Garg, Matteo Mazza et al.*

> In an effort to compete with the brain's efficiency at processing information, neuromorphic hardware combines artificial synapses and neurons using mixed-signal circuits and emerging memories. In ferroelectric resistive weights, the strength of the synaptic connection between two neurons is stored in the device conductance. During learning, programming pulses are applied to the synaptic weight, which reconfigures the ferroelectric domains and adjusts the conductance. One strategy to lower the energy cost during the training phase is to lower the duration of the programming pulses. However, the latter cannot be shorter than the self-loading time of the resistive weights, limited by intrinsic parasitics in the circuits. In this work, ferroelectric resistive weights are fabricated using a process compatible with CMOS Back-End-Of-Line integration, based on hafnia/zirconia nanolaminates. By laterally scaling the device area under 100 $Î¼$m$^2$, the self-loading time becomes sufficiently short to enable 20 ns programming, which corresponds to a maximum of 3 picoJoules per pulse. Further, in this work, the weight update rule with 20 ns pulses is experimentally measured not only for different amplitudes but also for different initial conductance states. We find that the final weight is determined by the pulse amplitude, independent of the initial weight value.

### [Ion Clustering Regulated by Extreme Nanoconfinement Enables Mechanosensitive Nanochannels](http://arxiv.org/abs/2601.01135v1)
**2026-01-03** | *Ke Zhou*

> Mechanosensitive ion nanochannels regulate transport by undergoing conformational changes within nanopores. However, achieving precise control over these conformational states remains a major challenge for both artificial soft or solid pores. Here, we propose an alternative mechanism that modulates the charge carrier density inside nanopores, inspired by transistors in solid-state electronics. This strategy leverages a novel phenomenon of confinement-regulated ion clustering in two-dimensional extremely confined nanochannels, revealed by extensive $Î¼$s-scale enhanced-sampling molecular simulations based on an \emph{ab initio}-refined force field and nucleation theory. The resulting \emph{force-ion transistor} enables mechanically gated control of ion transport and provides a conceptual foundation for designing ionic mechanical logic gates. Our findings offer new insights into piezochannel mechanosensing and electromechanical coupling in biosystems beyond conformational signaling, opening pathways to integrate artificial ion channels with neuromorphic devices for processing mechanical stimuli.

### [Color symmetry breaking in a nonlinear optical microcavity](http://arxiv.org/abs/2601.00792v1)
**2026-01-02** | *Luca O. TrinchÃ£o, Alekhya Ghosh, Arghadeep Pal et al.*

> Spontaneous symmetry breaking leads to diverse phenomena across the natural sciences, from the Higgs mechanism in particle physics to superconductors and collective animal behavior. In photonic systems, the symmetry of light states can be broken when two optical fields interact through the Kerr nonlinearity, as shown in early demonstrations with counterpropagating and cross-polarized modes. Here, we report the first observation of color symmetry breaking in an integrated silicon nitride microring, where spontaneous power imbalance arises between optical mode at different wavelengths, mediated by the Kerr effect. The threshold power for this effect is as low as 19 mW. By examining the system's homogeneous states, we further demonstrate a Kerr-based nonlinear activation-function generator that produces sigmoid-, quadratic-, and leaky-ReLU-like responses. These findings reveal previously unexplored nonlinear dynamics in dual-pumped Kerr resonators and establish new pathways towards compact, all-optical neuromorphic circuits.

### [SpikySpace: A Spiking State Space Model for Energy-Efficient Time Series Forecasting](http://arxiv.org/abs/2601.02411v1)
**2026-01-02** | *Kaiwen Tang, Jiaqi Zheng, Yuze Jin et al.*

> Time-series forecasting often operates under tight power and latency budgets in fields like traffic management, industrial condition monitoring, and on-device sensing. These applications frequently require near real-time responses and low energy consumption on edge devices. Spiking neural networks (SNNs) offer event-driven computation and ultra-low power by exploiting temporal sparsity and multiplication-free computation. Yet existing SNN-based time-series forecasters often inherit complex transformer blocks, thereby losing much of the efficiency benefit. To solve the problem, we propose SpikySpace, a spiking state-space model (SSM) that reduces the quadratic cost in the attention block to linear time via selective scanning. Further, we replace dense SSM updates with sparse spike trains and execute selective scans only on spike events, thereby avoiding dense multiplications while preserving the SSM's structured memory. Because complex operations such as exponentials and divisions are costly on neuromorphic chips, we introduce simplified approximations of SiLU and Softplus to enable a neuromorphic-friendly model architecture. In matched settings, SpikySpace reduces estimated energy consumption by 98.73% and 96.24% compared to two state-of-the-art transformer based approaches, namely iTransformer and iSpikformer, respectively. In standard time series forecasting datasets, SpikySpace delivers competitive accuracy while substantially reducing energy cost and memory traffic. As the first full spiking state-space model, SpikySpace bridges neuromorphic efficiency with modern sequence modeling, marking a practical and scalable path toward efficient time series forecasting systems.

### [Hardware Acceleration for Neural Networks: A Comprehensive Survey](http://arxiv.org/abs/2512.23914v2)
**2025-12-30** | *Bin Xu, Ayan Banerjee, Sandeep Gupta*

> Neural networks have become a dominant computational workload across cloud and edge platforms, but rapid growth in model size and deployment diversity has exposed hardware bottlenecks increasingly dominated by memory movement, communication, and irregular operators rather than peak arithmetic throughput. This survey reviews the technology landscape for hardware acceleration of deep learning, spanning GPUs and tensor-core architectures; domain-specific accelerators (e.g., TPUs/NPUs); FPGA-based designs; ASIC inference engines; and emerging LLM-serving accelerators such as LPUs (language processing units), alongside in-/near-memory computing and neuromorphic/analog approaches. We organize the space using a unified taxonomy across (i) workloads (CNNs, RNNs, GNNs, and Transformers/LLMs), (ii) execution settings (training vs.\ inference; datacenter vs.\ edge), and (iii) optimization levers (reduced precision, sparsity and pruning, operator fusion, compilation and scheduling, and memory-system/interconnect design). We synthesize key architectural ideas including systolic arrays, vector and SIMD engines, specialized attention and softmax kernels, quantization-aware datapaths, and high-bandwidth memory, and we discuss how software stacks and compilers bridge model semantics to hardware. Finally, we highlight open challenges -- including efficient long-context LLM inference (KV-cache management), robust support for dynamic and sparse workloads, energy- and security-aware deployment, and fair benchmarking -- and point to promising directions for the next generation of neural acceleration.

### [Mesoporous Thin Films as Nanoreactors for Complex Oxide Nanoparticle-based Devices](http://arxiv.org/abs/2512.23820v1)
**2025-12-29** | *S. Passanante, M. Quintero, A. Zelcer et al.*

> We combine for the first time the properties of ordered mesoporous thin films and complex oxide nanoparticles in the design of new heterostructures, taking advantage of the accessible tridimensional pores network. In this work, we demonstrate the feasibility of synthesizing La0.88Sr0.12MnO3 inside the pores of a mesoporous SiO2 thin film, using pulsed laser deposition. In order to understand the filling process, a set of samples were deposited for three different deposition times, on mesoporous and non-mesoporous SiO2 substrates. Their structural, magnetic, magnetocaloric and electrical transport properties were studied. All the results evidence the presence of the manganite compound inside the pores, which was confirmed by cross-section elemental mapping. X-ray reflectometry shows that it is possible to control the filling of the pores, keeping some accessible porosity. The magnetic behavior suggests the presence of weakly interacting ferromagnetic nanoparticles inside the pores. We provide here a successful strategy for the fabrication of complex oxide nanoparticles arrays with highly controlled size and ordering. Their easy incorporation into micro and nanofabrication procedures unveils direct implications in the field of interfaces and nanoparticle devices as diverse as energy conversion systems, solid oxide fuel cells, spintronics and neuromorphic memristor networks.

### [Enabling high giant magnetoresistance in ultrathin-free-layer spin valves](http://arxiv.org/abs/2512.22726v1)
**2025-12-27** | *Sachli Abdizadeh, Rachel E. Maizel, Jing Zhao et al.*

> Emerging spin-orbit-torque devices based on spin valves require an ultrathin (e.g., $\lesssim$2 nm) magnetic free layer to maximize the torque per moment. However, reducing the free-layer thickness deteriorates the giant magnetoresistance (GMR) signal for electrical readout. Here, we demonstrate that the addition of a 1-nm Cu seed layer enables high GMR ratios of 5-7% at free-layer thicknesses of $\lesssim$2 nm by promoting high-quality, textured growth of spin valves. Our work offers a pathway for engineering high-signal GMR readout in spin-orbit-torque digital memories and neuromorphic computers.

### [Protonic Nickelate Device Networks for Spatiotemporal Neuromorphic Computing](http://arxiv.org/abs/2512.22722v2)
**2025-12-27** | *Yue Zhou, Shaan Shah, Tamal Dey et al.*

> Computation in biological neural circuits arises from the interplay of nonlinear temporal responses and spatially distributed dynamic network interactions. Replicating this richness in hardware has remained challenging, as most neuromorphic devices emulate only isolated neuron- or synapse-like functions. In this work, we introduce an integrated neuromorphic computing platform in which both nonlinear spatiotemporal processing and programmable memory are realized within a single perovskite nickelate material system. By engineering symmetric and asymmetric hydrogenated NdNiO3 junction devices on the same wafer, we combine ultrafast, proton-mediated transient dynamics with stable multilevel resistance states. Networks of symmetric NdNiO3 junctions exhibit emergent spatial interactions mediated by proton redistribution, while each node simultaneously provides short-term temporal memory, enabling nanoseconds scale operation with an energy cost of 0.2 nJ per input. When interfaced with asymmetric output units serving as reconfigurable long-term weights, these networks allow both feature transformation and linear classification in the same material system. Leveraging these emergent interactions, the platform enables real-time pattern recognition and achieves high accuracy in spoken-digit classification and early seizure detection, outperforming temporal-only or uncoupled architectures. These results position protonic nickelates as a compact, energy-efficient, CMOS-compatible platform that integrates processing and memory for scalable intelligent hardware.

---

## ðŸ§  Algorithms & Theory

### [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](http://arxiv.org/abs/2601.05205v1)
**2026-01-08** | *Zain Iqbal, Lorenzo Valerio*

> Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

### [Bifurcation Analysis Framework of Spiking Neuron Models](http://arxiv.org/abs/2601.02116v1)
**2026-01-05** | *Zhiwei Li, Shi-Li Zhang, Chenyu Wen*

> Neuromorphic computing targets energy-efficient event-driven information processing by placing artificial spiking-neurons at its core. Artificial neuron devices and circuits have multiple operating modes and produce region-dependent nonlinear dynamics that are not captured by system analysis methods for linear systems, such as transfer functions, Fourier/Laplace transform, Bode diagram, etc. Thus, new tools are needed to evaluate the nonlinear behavior of neurons and to guide the design and optimization of artificial neuron implementations. Here we present a generalized bifurcation analysis framework based on nonlinear dynamical systems theory. A CMOS axon-hillock neuron, memristor neuron, and the FitzHugh-Nagumo biological neuron model are selected for demonstration. We evaluate Hopf bifurcation conditions to define the rest and firing domains in parameter space of the system, and predict the near-onset firing rate. The results are further compared with numerical simulations. The framework standardizes the analysis for various neuron models and physical realizations. It yields practical design and optimization guidelines for artificial neurons for neuromorphic computing systems, including parameter combinations to make a neuron fire/rest and to control the corresponding firing properties, e.g., firing rate and amplitude.

### [Three factor delay learning rules for spiking neural networks](http://arxiv.org/abs/2601.00668v1)
**2026-01-02** | *Luke Vassallo, Nima Taherinejad*

> Spiking Neural Networks (SNNs) are dynamical systems that operate on spatiotemporal data, yet their learnable parameters are often limited to synaptic weights, contributing little to temporal pattern recognition. Learnable parameters that delay spike times can improve classification performance in temporal tasks, but existing methods rely on large networks and offline learning, making them unsuitable for real-time operation in resource-constrained environments. In this paper, we introduce synaptic and axonal delays to leaky integrate and fire (LIF)-based feedforward and recurrent SNNs, and propose three-factor learning rules to simultaneously learn delay parameters online. We employ a smooth Gaussian surrogate to approximate spike derivatives exclusively for the eligibility trace calculation, and together with a top-down error signal determine parameter updates. Our experiments show that incorporating delays improves accuracy by up to 20% over a weights-only baseline, and for networks with similar parameter counts, jointly learning weights and delays yields up to 14% higher accuracy. On the SHD speech recognition dataset, our method achieves similar accuracy to offline backpropagation-based approaches. Compared to state-of-the-art methods, it reduces model size by 6.6x and inference latency by 67%, with only a 2.4% drop in classification accuracy. Our findings benefit the design of power and area-constrained neuromorphic processors by enabling on-device learning and lowering memory requirements.

### [Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing](http://arxiv.org/abs/2601.00245v2)
**2026-01-01** | *Osvaldo Simeone*

> The rapid growth of artificial intelligence (AI) has brought novel data processing and generative capabilities but also escalating energy requirements. This challenge motivates renewed interest in neuromorphic computing principles, which promise brain-like efficiency through discrete and sparse activations, recurrent dynamics, and non-linear feedback. In fact, modern AI architectures increasingly embody neuromorphic principles through heavily quantized activations, state-space dynamics, and sparse attention mechanisms. This paper elaborates on the connections between neuromorphic models, state-space models, and transformer architectures through the lens of the distinction between intra-token processing and inter-token processing. Most early work on neuromorphic AI was based on spiking neural networks (SNNs) for intra-token processing, i.e., for transformations involving multiple channels, or features, of the same vector input, such as the pixels of an image. In contrast, more recent research has explored how neuromorphic principles can be leveraged to design efficient inter-token processing methods, which selectively combine different information elements depending on their contextual relevance. Implementing associative memorization mechanisms, these approaches leverage state-space dynamics or sparse self-attention. Along with a systematic presentation of modern neuromorphic AI models through the lens of intra-token and inter-token processing, training methodologies for neuromorphic AI models are also reviewed. These range from surrogate gradients leveraging parallel convolutional processing to local learning rules based on reinforcement learning mechanisms.

### [Optical Spiking Neural Networks via Rogue-Wave Statistics](http://arxiv.org/abs/2512.24983v1)
**2025-12-31** | *BahadÄ±r Utku Kesgin, GÃ¼lsÃ¼m Yaren Durdu, UÄŸur TeÄŸin*

> Optical computing could reduce the energy cost of artificial intelligence by leveraging the parallelism and propagation speed of light. However, implementing nonlinear activation, essential for machine learning, remains challenging in low-power optical systems dominated by linear wave physics. Here, we introduce an optical spiking neural network that uses optical rogue-wave statistics as a programmable firing mechanism. By establishing a homomorphism between free-space diffraction and neuronal integration, we demonstrate that phase-engineered caustics enable robust, passive thresholding: sparse spatial spikes emerge when the local intensity exceeds a significant-intensity rogue-wave criterion. Using a physics-informed digital twin, we optimize granular phase masks to deterministically concentrate energy into targeted detector regions, enabling end-to-end co-design of the optical transformation and a lightweight electronic readout. We experimentally validate the approach on BreastMNIST and Olivetti Faces, achieving accuracies of 82.45\% and 95.00\%, respectively, competitive with standard digital baselines. These results demonstrate that extreme-wave phenomena, often treated as deleterious fluctuations, can be harnessed as structural nonlinearity for scalable, energy-efficient neuromorphic photonic inference.

### [SymSeqBench: a unified framework for the generation and analysis of rule-based symbolic sequences and datasets](http://arxiv.org/abs/2512.24977v1)
**2025-12-31** | *Barna Zajzon, Younes Bouhadjar, Maxime Fabre et al.*

> Sequential structure is a key feature of multiple domains of natural cognition and behavior, such as language, movement and decision-making. Likewise, it is also a central property of tasks to which we would like to apply artificial intelligence. It is therefore of great importance to develop frameworks that allow us to evaluate sequence learning and processing in a domain agnostic fashion, whilst simultaneously providing a link to formal theories of computation and computability. To address this need, we introduce two complementary software tools: SymSeq, designed to rigorously generate and analyze structured symbolic sequences, and SeqBench, a comprehensive benchmark suite of rule-based sequence processing tasks to evaluate the performance of artificial learning systems in cognitively relevant domains. In combination, SymSeqBench offers versatility in investigating sequential structure across diverse knowledge domains, including experimental psycholinguistics, cognitive psychology, behavioral analysis, neuromorphic computing and artificial intelligence. Due to its basis in Formal Language Theory (FLT), SymSeqBench provides researchers in multiple domains with a convenient and practical way to apply the concepts of FLT to conceptualize and standardize their experiments, thus advancing our understanding of cognition and behavior through shared computational frameworks and formalisms. The tool is modular, openly available and accessible to the research community.

### [Spiking Heterogeneous Graph Attention Networks](http://arxiv.org/abs/2601.02401v1)
**2025-12-31** | *Buqing Cao, Qian Peng, Xiang Xie et al.*

> Real-world graphs or networks are usually heterogeneous, involving multiple types of nodes and relationships. Heterogeneous graph neural networks (HGNNs) can effectively handle these diverse nodes and edges, capturing heterogeneous information within the graph, thus exhibiting outstanding performance. However, most methods of HGNNs usually involve complex structural designs, leading to problems such as high memory usage, long inference time, and extensive consumption of computing resources. These limitations pose certain challenges for the practical application of HGNNs, especially for resource-constrained devices. To mitigate this issue, we propose the Spiking Heterogeneous Graph Attention Networks (SpikingHAN), which incorporates the brain-inspired and energy-saving properties of Spiking Neural Networks (SNNs) into heterogeneous graph learning to reduce the computing cost without compromising the performance. Specifically, SpikingHAN aggregates metapath-based neighbor information using a single-layer graph convolution with shared parameters. It then employs a semantic-level attention mechanism to capture the importance of different meta-paths and performs semantic aggregation. Finally, it encodes the heterogeneous information into a spike sequence through SNNs, simulating bioinformatic processing to derive a binarized 1-bit representation of the heterogeneous graph. Comprehensive experimental results from three real-world heterogeneous graph datasets show that SpikingHAN delivers competitive node classification performance. It achieves this with fewer parameters, quicker inference, reduced memory usage, and lower energy consumption. Code is available at https://github.com/QianPeng369/SpikingHAN.

### [Exploring the Potential of Spiking Neural Networks in UWB Channel Estimation](http://arxiv.org/abs/2512.23975v1)
**2025-12-30** | *Youdong Zhang, Xu He, Xiaolin Meng*

> Although existing deep learning-based Ultra-Wide Band (UWB) channel estimation methods achieve high accuracy, their computational intensity clashes sharply with the resource constraints of low-cost edge devices. Motivated by this, this letter explores the potential of Spiking Neural Networks (SNNs) for this task and develops a fully unsupervised SNN solution. To enable a comprehensive performance analysis, we devise an extensive set of comparative strategies and evaluate them on a compelling public benchmark. Experimental results show that our unsupervised approach still attains 80% test accuracy, on par with several supervised deep learning-based strategies. Moreover, compared with complex deep learning methods, our SNN implementation is inherently suited to neuromorphic deployment and offers a drastic reduction in model complexity, bringing significant advantages for future neuromorphic practice.

### [U-Net-Like Spiking Neural Networks for Single Image Dehazing](http://arxiv.org/abs/2512.23950v1)
**2025-12-30** | *Huibin Li, Haoran Liu, Mingzhe Liu et al.*

> Image dehazing is a critical challenge in computer vision, essential for enhancing image clarity in hazy conditions. Traditional methods often rely on atmospheric scattering models, while recent deep learning techniques, specifically Convolutional Neural Networks (CNNs) and Transformers, have improved performance by effectively analyzing image features. However, CNNs struggle with long-range dependencies, and Transformers demand significant computational resources. To address these limitations, we propose DehazeSNN, an innovative architecture that integrates a U-Net-like design with Spiking Neural Networks (SNNs). DehazeSNN captures multi-scale image features while efficiently managing local and long-range dependencies. The introduction of the Orthogonal Leaky-Integrate-and-Fire Block (OLIFBlock) enhances cross-channel communication, resulting in superior dehazing performance with reduced computational burden. Our extensive experiments show that DehazeSNN is highly competitive to state-of-the-art methods on benchmark datasets, delivering high-quality haze-free images with a smaller model size and less multiply-accumulate operations. The proposed dehazing method is publicly available at https://github.com/HaoranLiu507/DehazeSNN.

### [Towards Reliable Evaluation of Adversarial Robustness for Spiking Neural Networks](http://arxiv.org/abs/2512.22522v1)
**2025-12-27** | *Jihang Wang, Dongcheng Zhao, Ruolin Chen et al.*

> Spiking Neural Networks (SNNs) utilize spike-based activations to mimic the brain's energy-efficient information processing. However, the binary and discontinuous nature of spike activations causes vanishing gradients, making adversarial robustness evaluation via gradient descent unreliable. While improved surrogate gradient methods have been proposed, their effectiveness under strong adversarial attacks remains unclear. We propose a more reliable framework for evaluating SNN adversarial robustness. We theoretically analyze the degree of gradient vanishing in surrogate gradients and introduce the Adaptive Sharpness Surrogate Gradient (ASSG), which adaptively evolves the shape of the surrogate function according to the input distribution during attack iterations, thereby enhancing gradient accuracy while mitigating gradient vanishing. In addition, we design an adversarial attack with adaptive step size under the $L_\infty$ constraint-Stable Adaptive Projected Gradient Descent (SA-PGD), achieving faster and more stable convergence under imprecise gradients. Extensive experiments show that our approach substantially increases attack success rates across diverse adversarial training schemes, SNN architectures and neuron models, providing a more generalized and reliable evaluation of SNN adversarial robustness. The experimental results further reveal that the robustness of current SNNs has been significantly overestimated and highlighting the need for more dependable adversarial training methods.

---

## ðŸ‘ï¸ Applications & Sensing

### [An Event-Based Opto-Tactile Skin](http://arxiv.org/abs/2601.03907v1)
**2026-01-07** | *Mohammadreza Koolani, Simeon Bamford, Petr Trunin et al.*

> This paper presents a neuromorphic, event-driven tactile sensing system for soft, large-area skin, based on the Dynamic Vision Sensors (DVS) integrated with a flexible silicone optical waveguide skin. Instead of repetitively scanning embedded photoreceivers, this design uses a stereo vision setup comprising two DVS cameras looking sideways through the skin. Such a design produces events as changes in brightness are detected, and estimates press positions on the 2D skin surface through triangulation, utilizing Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to find the center of mass of contact events resulting from pressing actions. The system is evaluated over a 4620 mm2 probed area of the skin using a meander raster scan. Across 95 % of the presses visible to both cameras, the press localization achieved a Root-Mean-Squared Error (RMSE) of 4.66 mm. The results highlight the potential of this approach for wide-area flexible and responsive tactile sensors in soft robotics and interactive environments. Moreover, we examined how the system performs when the amount of event data is strongly reduced. Using stochastic down-sampling, the event stream was reduced to 1/1024 of its original size. Under this extreme reduction, the average localization error increased only slightly (from 4.66 mm to 9.33 mm), and the system still produced valid press localizations for 85 % of the trials. This reduction in pass rate is expected, as some presses no longer produce enough events to form a reliable cluster for triangulation. These results show that the sensing approach remains functional even with very sparse event data, which is promising for reducing power consumption and computational load in future implementations. The system exhibits a detection latency distribution with a characteristic width of 31 ms.

### [STEMNIST: Spiking Tactile Extended MNIST Neuromorphic Dataset](http://arxiv.org/abs/2601.01658v1)
**2026-01-04** | *Anubhab Tripathi, Li Gaishan, Zhengnan Fu et al.*

> Tactile sensing is essential for robotic manipulation, prosthetics and assistive technologies, yet neuromorphic tactile datasets remain limited compared to their visual counterparts. We introduce STEMNIST, a large-scale neuromorphic tactile dataset extending ST-MNIST from 10 digits to 35 alphanumeric classes (uppercase letters A--Z and digits 1--9), providing a challenging benchmark for event-based haptic recognition. The dataset comprises 7,700 samples collected from 34 participants using a custom \(16\times 16\) tactile sensor array operating at 120 Hz, encoded as 1,005,592 spike events through adaptive temporal differentiation. Following EMNIST's visual character recognition protocol, STEMNIST addresses the critical gap between simplified digit classification and real-world tactile interaction scenarios requiring alphanumeric discrimination. Baseline experiments using conventional CNNs (90.91% test accuracy) and spiking neural networks (89.16%) establish performance benchmarks. The dataset's event-based format, unrestricted spatial variability and rich temporal structure makes it suitable for testing neuromorphic hardware and bio-inspired learning algorithms. STEMNIST enables reproducible evaluation of tactile recognition systems and provides a foundation for advancing energy-efficient neuromorphic perception in robotics, biomedical engineering and human-machine interfaces. The dataset, documentation and codes are publicly available to accelerate research in neuromorphic tactile computing.

### [LECalib: Line-Based Event Camera Calibration](http://arxiv.org/abs/2512.22441v1)
**2025-12-27** | *Zibin Liu, Banglei Guan, Yang Shang et al.*

> Camera calibration is an essential prerequisite for event-based vision applications. Current event camera calibration methods typically involve using flashing patterns, reconstructing intensity images, and utilizing the features extracted from events. Existing methods are generally time-consuming and require manually placed calibration objects, which cannot meet the needs of rapidly changing scenarios. In this paper, we propose a line-based event camera calibration framework exploiting the geometric lines of commonly-encountered objects in man-made environments, e.g., doors, windows, boxes, etc. Different from previous methods, our method detects lines directly from event streams and leverages an event-line calibration model to generate the initial guess of camera parameters, which is suitable for both planar and non-planar lines. Then, a non-linear optimization is adopted to refine camera parameters. Both simulation and real-world experiments have demonstrated the feasibility and accuracy of our method, with validation performed on monocular and stereo event cameras. The source code is released at https://github.com/Zibin6/line_based_event_camera_calib.

---

