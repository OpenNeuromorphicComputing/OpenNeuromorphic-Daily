# ðŸ§  Open Neuromorphic - Daily ArXiv

**Automated Daily Update** | Last Run: 2026-01-14 08:29 UTC

Papers are automatically categorized by topic and sorted by date.

## ðŸ›  Hardware & Materials

### [Dynamical stability by spin transfer in nearly isotropic magnets](http://arxiv.org/abs/2601.08738v1)
**2026-01-13** | *Hidekazu Kurebayashi, Joseph Barker, Takumi Yamazaki et al.*

> Spin transfer torques (STTs) control magnetisation by electric currents, enabling a range of nano-scale spintronic applications. They can destabilise the equilibrium magnetisation state by counteracting magnetic relaxation. Here, we maximise the STT effect through a dedicated growth-annealing protocol for CoFeB thin films, such that magnetic anisotropies originating from the interface and shape almost cancel each other. The nearly isotropic magnets enable low-current dynamical stabilisation of the magnetisation in the direction opposite to an applied magnetic field, thereby realising a spintronic analogue of the Kapitza pendulum. In an intermediate current regime, the STT drives large magnetisation vector fluctuations that cover the entire Bloch sphere. The continuous variable associated with the stochastic magnetisation direction may serve as a resource for probabilistic computing and neuromorphic hardware. Our results establish isotropic magnets as a platform to study as-yet-uncharted, far-from-equilibrium spin dynamics including anti-magnonics, with promising implications for unconventional computing paradigms.

### [Neuromorphic FPGA Design for Digital Signal Processing](http://arxiv.org/abs/2601.07069v1)
**2026-01-11** | *Justin London*

> In this paper, the foundations of neuromorphic computing, spiking neural networks (SNNs) and memristors, are analyzed and discussed. Neuromorphic computing is then applied to FPGA design for digital signal processing (DSP). Finite impulse response (FIR) and infinite impulse response (IIR) filters are implemented with and without neuromorphic computing in Vivado using Verilog HDL. The results suggest that neuromorphic computing can provide low-latency and synaptic plasticity thereby enabling continuous on-chip learning. Due to their parallel and event-driven nature, neuromorphic computing can reduce power consumption by eliminating von Neumann bottlenecks and improve efficiency, but at the cost of reduced numeric precision.

### [Thermally Configurable Multi-Order Polar Skyrmions in Multiferroic Oxide Superlattices](http://arxiv.org/abs/2601.05950v1)
**2026-01-09** | *Kefan Liu, Yuhui Huang, Xiangwei Guo et al.*

> Polar topological textures in low-dimensional ferroelectrics have emerged as a versatile platform for high-density information storage and neuromorphic computing. While low-order topological states, such as vortices and skyrmions, have been extensively studied, high-order polar topological families remain largely unexplored due to their higher energy requirements and limited stabilization methods. Here, using a BiFeO3 (BFO)-based multiferroic superlattice as a model system, we demonstrate a thermal-modulation strategy that stabilizes multi-order polar skyrmions and enables reversible tuning of their topological order through phase-field simulations. It was found that temperature modulation drives the system from polar solitons through 1Ï€-, 2Ï€-, 3Ï€-, and 4Ï€-skyrmion states, with closed heating-cooling path analyses revealing the widest thermal stability window for 2Ï€-skyrmions (up to 600 K). Leveraging this robustness, 2% Sm doping in BFO lowers the transition temperatures, enabling room-temperature stabilization of 2Ï€-skyrmions. These findings enrich the fundamental understanding of multi-order polar topologies and establish a tunable strategy for realizing variable-order topological configurations in practical memory devices.

### [Self-Evolving Distributed Memory Architecture for Scalable AI Systems](http://arxiv.org/abs/2601.05569v1)
**2026-01-09** | *Zixuan Li, Chuanzhen Wang, Haotian Sun*

> Distributed AI systems face critical memory management challenges across computation, communication, and deployment layers. RRAM based in memory computing suffers from scalability limitations due to device non idealities and fixed array sizes. Decentralized AI frameworks struggle with memory efficiency across NAT constrained networks due to static routing that ignores computational load. Multi agent deployment systems tightly couple application logic with execution environments, preventing adaptive memory optimization. These challenges stem from a fundamental lack of coordinated memory management across architectural layers. We introduce Self Evolving Distributed Memory Architecture for Scalable AI Systems, a three layer framework that unifies memory management across computation, communication, and deployment. Our approach features (1) memory guided matrix processing with dynamic partitioning based on device characteristics, (2) memory aware peer selection considering network topology and computational capacity, and (3) runtime adaptive deployment optimization through continuous reconfiguration. The framework maintains dual memory systems tracking both long term performance patterns and short term workload statistics. Experiments on COCO 2017, ImageNet, and SQuAD show that our method achieves 87.3 percent memory utilization efficiency and 142.5 operations per second compared to Ray Distributed at 72.1 percent and 98.7 operations per second, while reducing communication latency by 30.2 percent to 171.2 milliseconds and improving resource utilization to 82.7 percent. Our contributions include coordinated memory management across three architectural layers, workload adaptive resource allocation, and a dual memory architecture enabling dynamic system optimization.

### [Local Multimodal Dynamics in Mixed Ionic-Electronic Conductors and Their Fingerprints in Organic Electrochemical Transistor Operation](http://arxiv.org/abs/2601.05179v1)
**2026-01-08** | *Shubham Tanwar, Han-Yan Wu, Chi-Yuan Yang et al.*

> Mixed ionic-electronic conductors host tightly coupled interactions among mobile ions, electronic charges, and the polymer matrix, giving rise to complex multimodal responses spanning electrical, mechanical, and morphological transformations. These materials underpin organic electrochemical transistors (OECTs), which translate such interactions into low-voltage signal amplification and sensing for applications in bioelectronics, neuromorphic computing, and memory. Despite their central role, OECT current-voltage transfer characteristics are often treated phenomenologically, as both the local multimodal dynamics and their connection to global device response remain unresolved. Here, we reveal that the transfer curve encodes a cascade of spatially localized electrochemical transitions, each associated with distinct changes in conductivity, stiffness, and morphology, fundamentally redefining it as a spatially resolved fingerprint of device's internal state. Using automated operando multimodal in-liquid scanning dielectric microscopy, we directly map these dynamics and identify region-specific electrochemical thresholds governing the interplay between source, channel, and drain. We found that the local tip-sample electrostatic force serves as a remarkable mechanistic observable of coupled multimodal dynamics in mixed conductors. A physically grounded model links it to general material, interfacial, and geometric parameters, enabling mechanistic interpretation and predictive insights. Our work provides a new framework for probing and understanding mixed conduction in ion-electron coupled systems.

### [K-ion intercalation memristors in prussian blue analogs revealed by C-AFM for Non-Volatile memory and Neuromorphic Computing](http://arxiv.org/abs/2601.04724v1)
**2026-01-08** | *L. B. Avila, O. Leuve, M. Pohlitz et al.*

> Here, we demonstrate K-ion intercalation-mediated resistive switching in Prussian blue analogs (PBAs), a mechanism widely exploited in potassium batteries but not previously resolved at the nanoscale for memristive operation. Using C-AFM, we directly visualize and electrically control this intercalation process within sub-100-nm volumes, revealing reversible, localized conductance modulation driven by K-ion intercalation and Fe2+/Fe3+ redox reconfiguration. This nanoscale operability highlights the exceptional potential of PBAs for high-scalable and low-dimension memristor-based devices integration. Due to their modular composition, PBAs constitute a chemically rich, earth-abundant materials platform whose electronic and ionic properties can be precisely tuned for specific device functions. K-ion intercalation PBA-based memristor devices, with their singlestep, aqueous, and room-temperature fabrication, enable low-cost, large-scale processing compatible with CMOS, without any additional post-fabrication processing. Our findings establish PBAs as a new class of intercalation memristors with scalable nanoscale switching and exceptional materials versatility, toward highly integrated neuromorphic and non-volatile memory technologies. This work provides the first demonstration of intercalation-driven resistive switching under ultrafast voltage sweeps, with PW operating up to 200 V/s and PB up to 50 V/s. This unprecedented speed establishes PBAs as a distinct, high-rate class of K-ion intercalation memristors suitable for fast, high-density neuromorphic and memory applications.

### [Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing](http://arxiv.org/abs/2601.04476v1)
**2026-01-08** | *Chuanzhen Wang, Leo Zhang, Eric Liu*

> Recent hardware acceleration advances have enabled powerful specialized accelerators for finite element computations, spiking neural network inference, and sparse tensor operations. However, existing approaches face fundamental limitations: (1) finite element methods lack comprehensive rounding error analysis for reduced-precision implementations and use fixed precision assignment strategies that cannot adapt to varying numerical conditioning; (2) spiking neural network accelerators cannot handle non-spike operations and suffer from bit-width escalation as network depth increases; and (3) FPGA tensor accelerators optimize only for dense computations while requiring manual configuration for each sparsity pattern. To address these challenges, we introduce \textbf{Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing}, a novel framework that integrates three enhanced modules with memory-guided adaptation for efficient mixed-workload processing on unified platforms. Our approach employs memory-guided precision selection to overcome fixed precision limitations, integrates experience-driven bit-width management and dynamic parallelism adaptation for enhanced spiking neural network acceleration, and introduces curriculum learning for automatic sparsity pattern discovery. Extensive experiments on FEniCS, COMSOL, ANSYS benchmarks, MNIST, CIFAR-10, CIFAR-100, DVS-Gesture datasets, and COCO 2017 demonstrate 2.8\% improvement in numerical accuracy, 47\% throughput increase, 34\% energy reduction, and 45-65\% throughput improvement compared to specialized accelerators. Our work enables unified processing of finite element methods, spiking neural networks, and sparse computations on a single platform while eliminating data transfer overhead between separate units.

### [A Quantifiable Information-Processing Hierarchy Provides a Necessary Condition for Detecting Agency](http://arxiv.org/abs/2601.03498v1)
**2026-01-07** | *Brett J. Kagan, Valentina Baccetti, Brian D. Earp et al.*

> As intelligent systems are developed across diverse substrates - from machine learning models and neuromorphic hardware to in vitro neural cultures - understanding what gives a system agency has become increasingly important. Existing definitions, however, tend to rely on top-down descriptions that are difficult to quantify. We propose a bottom-up framework grounded in a system's information-processing order: the extent to which its transformation of input evolves over time. We identify three orders of information processing. Class I systems are reactive and memoryless, mapping inputs directly to outputs. Class II systems incorporate internal states that provide memory but follow fixed transformation rules. Class III systems are adaptive; their transformation rules themselves change as a function of prior activity. While not sufficient on their own, these dynamics represent necessary informational conditions for genuine agency. This hierarchy offers a measurable, substrate-independent way to identify the informational precursors of agency. We illustrate the framework with neurophysiological and computational examples, including thermostats and receptor-like memristors, and discuss its implications for the ethical and functional evaluation of systems that may exhibit agency.

### [Integrated magnonic chip using cascaded logic](http://arxiv.org/abs/2601.02644v1)
**2026-01-06** | *Mengying Guo, Xudong Jing, KristÃ½na DavÃ­dkovÃ¡ et al.*

> The transistor transformed not only electronics but everyday life, and the integrated circuit - now simply the "chip" - made computation scalable and ubiquitous. Magnonics has long promised a parallel path to low-energy information processing by using spin waves instead of charge. Progress, however, has been limited by two fundamental obstacles: intrinsic attenuation of spin waves and the requirement for precisely normalised output intensity and input phase to ensure reliable logic operation - conditions that are difficult to maintain in large-scale circuits owing to inevitable imperfections. Here, we report an integrated magnonic circuit that overcomes both limitations through engineered nonlinearity in nanoscale yttrium iron garnet waveguides. Nonlinear self-adjustment of the spin wave phase renders logic operation insensitive to the relative phases of the inputs, while a deeply nonlinear, threshold-activated self-normalised excitation restores and standardises the output intensity. Using space-resolved micro-focused Brillouin light scattering, we demonstrate reconfigurable AND, OR and three-input majority gates and realise deterministic cascading across sequential stages, establishing a scalable on-chip logic primitive. The architecture operates with gigahertz frequencies, supports dynamic threshold control for functional reconfiguration, and is compatible with scalable integration, making it attractive for adaptive and neuromorphic computing. By resolving phase-independent operation and signal restoration at the level of device physics, this work advances magnonics from isolated proof-of-concept devices towards integrated magnonic chips that can complement advanced CMOS in energy-constrained computing tasks.

### [Sparsity-Aware Streaming SNN Accelerator with Output-Channel Dataflow for Automatic Modulation Classification](http://arxiv.org/abs/2601.02613v1)
**2026-01-06** | *Kuilian Yang, Li Zhang, Ahmed M. Eltawil et al.*

> The rapid advancement of wireless communication technologies, including 5G, emerging 6G networks, and the large-scale deployment of the Internet of Things (IoT), has intensified the need for efficient spectrum utilization. Automatic modulation classification (AMC) plays a vital role in cognitive radio systems by enabling real-time identification of modulation schemes for dynamic spectrum access and interference mitigation. While deep neural networks (DNNs) offer high classification accuracy, their computational and energy demands pose challenges for real-time edge deployment. Spiking neural networks (SNNs), with their event-driven nature, offer inherent energy efficiency, but achieving both high throughput and low power under constrained hardware resources remains challenging. This work proposes a sparsity-aware SNN streaming accelerator optimized for AMC tasks. Unlike traditional systolic arrays that exploit sparsity but suffer from low throughput, or streaming architectures that achieve high throughput but cannot fully utilize input and weight sparsity, our design integrates both advantages. By leveraging the fixed nature of kernels during inference, we apply the gated one-to-all product (GOAP) algorithm to compute only on non-zero input-weight intersections. Extra or empty iterations are precomputed and embedded into the inference dataflow, eliminating dynamic data fetches and enabling fully pipelined, control-free inter-layer execution. Implemented on an FPGA, our sparsity-aware output-channel dataflow streaming (SAOCDS) accelerator achieves 23.5 MS/s (approximately double the baseline throughput) on the RadioML 2016 dataset, while reducing dynamic power and maintaining comparable classification accuracy. These results demonstrate strong potential for real-time, low-power deployment in edge cognitive radio systems.

### [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](http://arxiv.org/abs/2601.02253v1)
**2026-01-05** | *Emrah Mete, Emin Erkan Korkmaz*

> The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

### [Toward Thermodynamic Reservoir Computing: Exploring SHA-256 ASICs as Potential Physical Substrates](http://arxiv.org/abs/2601.01916v1)
**2026-01-05** | *Francisco Angulo de Lafuente, Vladimir Veselov, Richard Goodman*

> We propose a theoretical framework--Holographic Reservoir Computing (HRC)--which hypothesizes that the thermodynamic noise and timing dynamics in voltage-stressed Bitcoin mining ASICs (BM1366) could potentially serve as a physical reservoir computing substrate. We present the CHIMERA (Conscious Hybrid Intelligence via Miner-Embedded Resonance Architecture) system architecture, which treats the SHA-256 hashing pipeline not as an entropy source, but as a deterministic diffusion operator whose timing characteristics under controlled voltage and frequency conditions may exhibit computationally useful dynamics. We report preliminary observations of non-Poissonian variability in inter-arrival time statistics during edge-of-stability operation, which we term the "Silicon Heartbeat" hypothesis. Theoretical analysis based on Hierarchical Number System (HNS) representations suggests that such architectures could achieve O(log n) energy scaling compared to traditional von Neumann O(2^n) dependencies. However, we emphasize that these are theoretical projections requiring experimental validation. We present the implemented measurement infrastructure, acknowledge current limitations, and outline the experimental program necessary to confirm or refute these hypotheses. This work contributes to the emerging field of thermodynamic computing by proposing a novel approach to repurposing obsolete cryptographic hardware for neuromorphic applications.

### [Image Synthesis Using Spintronic Deep Convolutional Generative Adversarial Network](http://arxiv.org/abs/2601.01441v1)
**2026-01-04** | *Saumya Gupta, Abhinandan, Venkatesh vadde et al.*

> The computational requirements of generative adversarial networks (GANs) exceed the limit of conventional Von Neumann architectures, necessitating energy efficient alternatives such as neuromorphic spintronics. This work presents a hybrid CMOS-spintronic deep convolutional generative adversarial network (DCGAN) architecture for synthetic image generation. The proposed generative vision model approach follows the standard framework, leveraging generator and discriminators adversarial training with our designed spintronics hardware for deconvolution, convolution, and activation layers of the DCGAN architecture. To enable hardware aware spintronic implementation, the generator's deconvolution layers are restructured as zero padded convolution, allowing seamless integration with a 6-bit skyrmion based synapse in a crossbar, without compromising training performance. Nonlinear activation functions are implemented using a hybrid CMOS domain wall based Rectified linear unit (ReLU) and Leaky ReLU units. Our proposed tunable Leaky ReLU employs domain wall position coded, continuous resistance states and a piecewise uniaxial parabolic anisotropy profile with a parallel MTJ readout, exhibiting energy consumption of 0.192 pJ. Our spintronic DCGAN model demonstrates adaptability across both grayscale and colored datasets, achieving Fr'echet Inception Distances (FID) of 27.5 for the Fashion MNIST and 45.4 for Anime Face datasets, with testing energy (training energy) of 4.9 nJ (14.97~nJ/image) and 24.72 nJ (74.7 nJ/image).

### [Analog Weight Update Rule in Ferroelectric Hafnia, using pico-Joule Programming Pulses](http://arxiv.org/abs/2601.01186v1)
**2026-01-03** | *Alexandre Baigol, Nikhil Garg, Matteo Mazza et al.*

> In an effort to compete with the brain's efficiency at processing information, neuromorphic hardware combines artificial synapses and neurons using mixed-signal circuits and emerging memories. In ferroelectric resistive weights, the strength of the synaptic connection between two neurons is stored in the device conductance. During learning, programming pulses are applied to the synaptic weight, which reconfigures the ferroelectric domains and adjusts the conductance. One strategy to lower the energy cost during the training phase is to lower the duration of the programming pulses. However, the latter cannot be shorter than the self-loading time of the resistive weights, limited by intrinsic parasitics in the circuits. In this work, ferroelectric resistive weights are fabricated using a process compatible with CMOS Back-End-Of-Line integration, based on hafnia/zirconia nanolaminates. By laterally scaling the device area under 100 $Î¼$m$^2$, the self-loading time becomes sufficiently short to enable 20 ns programming, which corresponds to a maximum of 3 picoJoules per pulse. Further, in this work, the weight update rule with 20 ns pulses is experimentally measured not only for different amplitudes but also for different initial conductance states. We find that the final weight is determined by the pulse amplitude, independent of the initial weight value.

### [Ion Clustering Regulated by Extreme Nanoconfinement Enables Mechanosensitive Nanochannels](http://arxiv.org/abs/2601.01135v1)
**2026-01-03** | *Ke Zhou*

> Mechanosensitive ion nanochannels regulate transport by undergoing conformational changes within nanopores. However, achieving precise control over these conformational states remains a major challenge for both artificial soft or solid pores. Here, we propose an alternative mechanism that modulates the charge carrier density inside nanopores, inspired by transistors in solid-state electronics. This strategy leverages a novel phenomenon of confinement-regulated ion clustering in two-dimensional extremely confined nanochannels, revealed by extensive $Î¼$s-scale enhanced-sampling molecular simulations based on an \emph{ab initio}-refined force field and nucleation theory. The resulting \emph{force-ion transistor} enables mechanically gated control of ion transport and provides a conceptual foundation for designing ionic mechanical logic gates. Our findings offer new insights into piezochannel mechanosensing and electromechanical coupling in biosystems beyond conformational signaling, opening pathways to integrate artificial ion channels with neuromorphic devices for processing mechanical stimuli.

### [Color symmetry breaking in a nonlinear optical microcavity](http://arxiv.org/abs/2601.00792v1)
**2026-01-02** | *Luca O. TrinchÃ£o, Alekhya Ghosh, Arghadeep Pal et al.*

> Spontaneous symmetry breaking leads to diverse phenomena across the natural sciences, from the Higgs mechanism in particle physics to superconductors and collective animal behavior. In photonic systems, the symmetry of light states can be broken when two optical fields interact through the Kerr nonlinearity, as shown in early demonstrations with counterpropagating and cross-polarized modes. Here, we report the first observation of color symmetry breaking in an integrated silicon nitride microring, where spontaneous power imbalance arises between optical mode at different wavelengths, mediated by the Kerr effect. The threshold power for this effect is as low as 19 mW. By examining the system's homogeneous states, we further demonstrate a Kerr-based nonlinear activation-function generator that produces sigmoid-, quadratic-, and leaky-ReLU-like responses. These findings reveal previously unexplored nonlinear dynamics in dual-pumped Kerr resonators and establish new pathways towards compact, all-optical neuromorphic circuits.

### [SpikySpace: A Spiking State Space Model for Energy-Efficient Time Series Forecasting](http://arxiv.org/abs/2601.02411v1)
**2026-01-02** | *Kaiwen Tang, Jiaqi Zheng, Yuze Jin et al.*

> Time-series forecasting often operates under tight power and latency budgets in fields like traffic management, industrial condition monitoring, and on-device sensing. These applications frequently require near real-time responses and low energy consumption on edge devices. Spiking neural networks (SNNs) offer event-driven computation and ultra-low power by exploiting temporal sparsity and multiplication-free computation. Yet existing SNN-based time-series forecasters often inherit complex transformer blocks, thereby losing much of the efficiency benefit. To solve the problem, we propose SpikySpace, a spiking state-space model (SSM) that reduces the quadratic cost in the attention block to linear time via selective scanning. Further, we replace dense SSM updates with sparse spike trains and execute selective scans only on spike events, thereby avoiding dense multiplications while preserving the SSM's structured memory. Because complex operations such as exponentials and divisions are costly on neuromorphic chips, we introduce simplified approximations of SiLU and Softplus to enable a neuromorphic-friendly model architecture. In matched settings, SpikySpace reduces estimated energy consumption by 98.73% and 96.24% compared to two state-of-the-art transformer based approaches, namely iTransformer and iSpikformer, respectively. In standard time series forecasting datasets, SpikySpace delivers competitive accuracy while substantially reducing energy cost and memory traffic. As the first full spiking state-space model, SpikySpace bridges neuromorphic efficiency with modern sequence modeling, marking a practical and scalable path toward efficient time series forecasting systems.

---

## ðŸ§  Algorithms & Theory

### [Supervised Spike Agreement Dependent Plasticity for Fast Local Learning in Spiking Neural Networks](http://arxiv.org/abs/2601.08526v1)
**2026-01-13** | *Gouri Lakshmi S, Athira Chandrasekharan, Harshit Kumar et al.*

> Spike-Timing-Dependent Plasticity (STDP) provides a biologically grounded learning rule for spiking neural networks (SNNs), but its reliance on precise spike timing and pairwise updates limits fast learning of weights. We introduce a supervised extension of Spike Agreement-Dependent Plasticity (SADP), which replaces pairwise spike-timing comparisons with population-level agreement metrics such as Cohen's kappa. The proposed learning rule preserves strict synaptic locality, admits linear-time complexity, and enables efficient supervised learning without backpropagation, surrogate gradients, or teacher forcing.   We integrate supervised SADP within hybrid CNN-SNN architectures, where convolutional encoders provide compact feature representations that are converted into Poisson spike trains for agreement-driven learning in the SNN. Extensive experiments on MNIST, Fashion-MNIST, CIFAR-10, and biomedical image classification tasks demonstrate competitive performance and fast convergence. Additional analyses show stable performance across broad hyperparameter ranges and compatibility with device-inspired synaptic update dynamics. Together, these results establish supervised SADP as a scalable, biologically grounded, and hardware-aligned learning paradigm for spiking neural networks.

### [Sleep-Based Homeostatic Regularization for Stabilizing Spike-Timing-Dependent Plasticity in Recurrent Spiking Neural Networks](http://arxiv.org/abs/2601.08447v1)
**2026-01-13** | *Andreas Massey, Aliaksandr Hubin, Stefano Nichele et al.*

> Spike-timing-dependent plasticity (STDP) provides a biologically-plausible learning mechanism for spiking neural networks (SNNs); however, Hebbian weight updates in architectures with recurrent connections suffer from pathological weight dynamics: unbounded growth, catastrophic forgetting, and loss of representational diversity. We propose a neuromorphic regularization scheme inspired by the synaptic homeostasis hypothesis: periodic offline phases during which external inputs are suppressed, synaptic weights undergo stochastic decay toward a homeostatic baseline, and spontaneous activity enables memory consolidation. We demonstrate that this sleep-wake cycle prevents weight saturation while preserving learned structure. Empirically, we find that low to intermediate sleep durations (10-20\% of training) improve stability on MNIST-like benchmarks in our STDP-SNN model, without any data-specific hyperparameter tuning. In contrast, the same sleep intervention yields no measurable benefit for the surrogate-gradient spiking neural network (SG-SNN). Taken together, these results suggest that periodic, sleep-based renormalization may represent a fundamental mechanism for stabilizing local Hebbian learning in neuromorphic systems, while also indicating that special care is required when integrating such protocols with existing gradient-based optimization methods.

### [Spiking Neural-Invariant Kalman Fusion for Accurate Localization Using Low-Cost IMUs](http://arxiv.org/abs/2601.08248v1)
**2026-01-13** | *Yaohua Liu, Qiao Xu, Yemin Wang et al.*

> Low-cost inertial measurement units (IMUs) are widely utilized in mobile robot localization due to their affordability and ease of integration. However, their complex, nonlinear, and time-varying noise characteristics often lead to significant degradation in localization accuracy when applied directly for dead reckoning. To overcome this limitation, we propose a novel brain-inspired state estimation framework that combines a spiking neural network (SNN) with an invariant extended Kalman filter (InEKF). The SNN is designed to extract motion-related features from long sequences of IMU data affected by substantial random noise and is trained via a surrogate gradient descent algorithm to enable dynamic adaptation of the covariance noise parameter within the InEKF. By fusing the SNN output with raw IMU measurements, the proposed method enhances the robustness and accuracy of pose estimation. Extensive experiments conducted on the KITTI dataset and real-world data collected using a mobile robot equipped with a low-cost IMU demonstrate that the proposed approach outperforms state-of-the-art methods in localization accuracy and exhibits strong robustness to sensor noise, highlighting its potential for real-world mobile robot applications.

### [A brain-inspired information fusion method for enhancing robot GPS outages navigation](http://arxiv.org/abs/2601.08244v1)
**2026-01-13** | *Yaohua Liu, Hengjun Zhang, Binkai Ou*

> Low-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages both current and historical IMU data to estimate vehicle motion. The effectiveness of the proposed method is evaluated through real-world field tests and experiments on public datasets. Compared to conventional deep learning approaches, the results demonstrate that BGFN achieves higher accuracy and enhanced reliability in navigation performance, particularly under prolonged GPS outages.

### [The Potential Impact of Neuromorphic Computing on Radio Telescope Observatories](http://arxiv.org/abs/2601.07130v1)
**2026-01-12** | *Nicholas J. Pritchard, Richard Dodson, Andreas Wicenec*

> Radio astronomy relies on bespoke, experimental and innovative computing solutions. This will continue as next-generation telescopes such as the Square Kilometre Array (SKA) and next-generation Very Large Array (ngVLA) take shape. Under increasingly demanding power consumption, and increasingly challenging radio environments, science goals may become intractable with conventional von Neumann computing due to related power requirements. Neuromorphic computing offers a compelling alternative, and combined with a desire for data-driven methods, Spiking Neural Networks (SNNs) are a promising real-time power-efficient alternative. Radio Frequency Interference (RFI) detection is an attractive use-case for SNNs where recent exploration holds promise. This work presents a comprehensive analysis of the potential impact of deploying varying neuromorphic approaches across key stages in radio astronomy processing pipelines for several existing and near-term instruments. Our analysis paves a realistic path from near-term FPGA deployment of SNNs in existing instruments, allowing the addition of advanced data-driven RFI detection for no capital cost, to neuromorphic ASICs for future instruments, finding that commercially available solutions could reduce the power budget for key processing elements by up to three orders of magnitude, transforming the operational budget of the observatory. High-data-rate spectrographic processing could be a well-suited target for the neuromorphic computing industry, as we cast radio telescopes as the world's largest in-sensor compute challenge.

### [Efficient Aspect Term Extraction using Spiking Neural Network](http://arxiv.org/abs/2601.06637v1)
**2026-01-10** | *Abhishek Kumar Mishra, Arya Somasundaram, Anup Das et al.*

> Aspect Term Extraction (ATE) identifies aspect terms in review sentences, a key subtask of sentiment analysis. While most existing approaches use energy-intensive deep neural networks (DNNs) for ATE as sequence labeling, this paper proposes a more energy-efficient alternative using Spiking Neural Networks (SNNs). Using sparse activations and event-driven inferences, SNNs capture temporal dependencies between words, making them suitable for ATE. The proposed architecture, SpikeATE, employs ternary spiking neurons and direct spike training fine-tuned with pseudo-gradients. Evaluated on four benchmark SemEval datasets, SpikeATE achieves performance comparable to state-of-the-art DNNs with significantly lower energy consumption. This highlights the use of SNNs as a practical and sustainable choice for ATE tasks.

### [Nonlinear mode interactions under parametric excitation in a YIG microdisk](http://arxiv.org/abs/2601.05775v1)
**2026-01-09** | *Gabriel Soares, Rafael Lopes Seeger, Amel Kolli et al.*

> A pair of quantized spin-wave modes is driven by two-tone parallel pumping in a YIG microdisk. The nonlinear dynamics is experimentally investigated by probing the resulting steady state, which is found to critically depend on the chosen pair of modes, the detuning between the pump frequencies and the modes parametric resonance, as well as the temporal sequence of the two rf tones. A general theory of parametric excitation in confined structures based on magnetization normal modes is developed and quantitatively accounts for the observed dependence and non-commutative behaviors, which emerge from the interplay between the self and mutual nonlinear frequency shifts of the spin-wave modes. Owing to its high degree of external controllability and scalability to larger sets of modes, this dynamical system provides a model platform for exploring nonlinear phenomena and a promising route toward rf driven state mapping relevant to neuromorphic and unconventional computing.

### [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](http://arxiv.org/abs/2601.05205v1)
**2026-01-08** | *Zain Iqbal, Lorenzo Valerio*

> Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

### [Bifurcation Analysis Framework of Spiking Neuron Models](http://arxiv.org/abs/2601.02116v1)
**2026-01-05** | *Zhiwei Li, Shi-Li Zhang, Chenyu Wen*

> Neuromorphic computing targets energy-efficient event-driven information processing by placing artificial spiking-neurons at its core. Artificial neuron devices and circuits have multiple operating modes and produce region-dependent nonlinear dynamics that are not captured by system analysis methods for linear systems, such as transfer functions, Fourier/Laplace transform, Bode diagram, etc. Thus, new tools are needed to evaluate the nonlinear behavior of neurons and to guide the design and optimization of artificial neuron implementations. Here we present a generalized bifurcation analysis framework based on nonlinear dynamical systems theory. A CMOS axon-hillock neuron, memristor neuron, and the FitzHugh-Nagumo biological neuron model are selected for demonstration. We evaluate Hopf bifurcation conditions to define the rest and firing domains in parameter space of the system, and predict the near-onset firing rate. The results are further compared with numerical simulations. The framework standardizes the analysis for various neuron models and physical realizations. It yields practical design and optimization guidelines for artificial neurons for neuromorphic computing systems, including parameter combinations to make a neuron fire/rest and to control the corresponding firing properties, e.g., firing rate and amplitude.

### [Three factor delay learning rules for spiking neural networks](http://arxiv.org/abs/2601.00668v1)
**2026-01-02** | *Luke Vassallo, Nima Taherinejad*

> Spiking Neural Networks (SNNs) are dynamical systems that operate on spatiotemporal data, yet their learnable parameters are often limited to synaptic weights, contributing little to temporal pattern recognition. Learnable parameters that delay spike times can improve classification performance in temporal tasks, but existing methods rely on large networks and offline learning, making them unsuitable for real-time operation in resource-constrained environments. In this paper, we introduce synaptic and axonal delays to leaky integrate and fire (LIF)-based feedforward and recurrent SNNs, and propose three-factor learning rules to simultaneously learn delay parameters online. We employ a smooth Gaussian surrogate to approximate spike derivatives exclusively for the eligibility trace calculation, and together with a top-down error signal determine parameter updates. Our experiments show that incorporating delays improves accuracy by up to 20% over a weights-only baseline, and for networks with similar parameter counts, jointly learning weights and delays yields up to 14% higher accuracy. On the SHD speech recognition dataset, our method achieves similar accuracy to offline backpropagation-based approaches. Compared to state-of-the-art methods, it reduces model size by 6.6x and inference latency by 67%, with only a 2.4% drop in classification accuracy. Our findings benefit the design of power and area-constrained neuromorphic processors by enabling on-device learning and lowering memory requirements.

### [Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing](http://arxiv.org/abs/2601.00245v3)
**2026-01-01** | *Osvaldo Simeone*

> The rapid growth of artificial intelligence (AI) has brought novel data processing and generative capabilities but also escalating energy requirements. This challenge motivates renewed interest in neuromorphic computing principles, which promise brain-like efficiency through discrete and sparse activations, recurrent dynamics, and non-linear feedback. In fact, modern AI architectures increasingly embody neuromorphic principles through heavily quantized activations, state-space dynamics, and sparse attention mechanisms. This paper elaborates on the connections between neuromorphic models, state-space models, and transformer architectures through the lens of the distinction between intra-token processing and inter-token processing. Most early work on neuromorphic AI was based on spiking neural networks (SNNs) for intra-token processing, i.e., for transformations involving multiple channels, or features, of the same vector input, such as the pixels of an image. In contrast, more recent research has explored how neuromorphic principles can be leveraged to design efficient inter-token processing methods, which selectively combine different information elements depending on their contextual relevance. Implementing associative memorization mechanisms, these approaches leverage state-space dynamics or sparse self-attention. Along with a systematic presentation of modern neuromorphic AI models through the lens of intra-token and inter-token processing, training methodologies for neuromorphic AI models are also reviewed. These range from surrogate gradients leveraging parallel convolutional processing to local learning rules based on reinforcement learning mechanisms.

---

## ðŸ‘ï¸ Applications & Sensing

### [An Event-Based Opto-Tactile Skin](http://arxiv.org/abs/2601.03907v1)
**2026-01-07** | *Mohammadreza Koolani, Simeon Bamford, Petr Trunin et al.*

> This paper presents a neuromorphic, event-driven tactile sensing system for soft, large-area skin, based on the Dynamic Vision Sensors (DVS) integrated with a flexible silicone optical waveguide skin. Instead of repetitively scanning embedded photoreceivers, this design uses a stereo vision setup comprising two DVS cameras looking sideways through the skin. Such a design produces events as changes in brightness are detected, and estimates press positions on the 2D skin surface through triangulation, utilizing Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to find the center of mass of contact events resulting from pressing actions. The system is evaluated over a 4620 mm2 probed area of the skin using a meander raster scan. Across 95 % of the presses visible to both cameras, the press localization achieved a Root-Mean-Squared Error (RMSE) of 4.66 mm. The results highlight the potential of this approach for wide-area flexible and responsive tactile sensors in soft robotics and interactive environments. Moreover, we examined how the system performs when the amount of event data is strongly reduced. Using stochastic down-sampling, the event stream was reduced to 1/1024 of its original size. Under this extreme reduction, the average localization error increased only slightly (from 4.66 mm to 9.33 mm), and the system still produced valid press localizations for 85 % of the trials. This reduction in pass rate is expected, as some presses no longer produce enough events to form a reliable cluster for triangulation. These results show that the sensing approach remains functional even with very sparse event data, which is promising for reducing power consumption and computational load in future implementations. The system exhibits a detection latency distribution with a characteristic width of 31 ms.

### [STEMNIST: Spiking Tactile Extended MNIST Neuromorphic Dataset](http://arxiv.org/abs/2601.01658v1)
**2026-01-04** | *Anubhab Tripathi, Li Gaishan, Zhengnan Fu et al.*

> Tactile sensing is essential for robotic manipulation, prosthetics and assistive technologies, yet neuromorphic tactile datasets remain limited compared to their visual counterparts. We introduce STEMNIST, a large-scale neuromorphic tactile dataset extending ST-MNIST from 10 digits to 35 alphanumeric classes (uppercase letters A--Z and digits 1--9), providing a challenging benchmark for event-based haptic recognition. The dataset comprises 7,700 samples collected from 34 participants using a custom \(16\times 16\) tactile sensor array operating at 120 Hz, encoded as 1,005,592 spike events through adaptive temporal differentiation. Following EMNIST's visual character recognition protocol, STEMNIST addresses the critical gap between simplified digit classification and real-world tactile interaction scenarios requiring alphanumeric discrimination. Baseline experiments using conventional CNNs (90.91% test accuracy) and spiking neural networks (89.16%) establish performance benchmarks. The dataset's event-based format, unrestricted spatial variability and rich temporal structure makes it suitable for testing neuromorphic hardware and bio-inspired learning algorithms. STEMNIST enables reproducible evaluation of tactile recognition systems and provides a foundation for advancing energy-efficient neuromorphic perception in robotics, biomedical engineering and human-machine interfaces. The dataset, documentation and codes are publicly available to accelerate research in neuromorphic tactile computing.

---

