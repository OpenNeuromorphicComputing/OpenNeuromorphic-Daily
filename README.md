# ðŸ§  Open Neuromorphic - Daily ArXiv

**Automated Daily Update** | Last Run: 2026-01-26 08:32 UTC

Papers are automatically categorized by topic and sorted by date.

## ðŸ›  Hardware & Materials

### [Engineering the electronic structure of TiO$_2$ by transition metal doping: A First Principles DFT Study](http://arxiv.org/abs/2601.16735v1)
**2026-01-23** | *Vikash Mishra, Shashi Pandey, Swaroop Ganguly et al.*

> By means of first-principles density-functional theory (DFT) calculations, we perform a comparative analysis of the electronic and magnetic properties of transition metal-doped TiO$_2$. The electronic band gaps of Ti$_x$M$_{1-x}$O$_2$, where M represents 3d-transition metals such as Sc, V, Cr, Mn, Fe, Co, Ni, Cu, and Zn have been determined using the PBE functional within the generalized-gradient approximation (GGA) scheme, and also using the hybrid HSE06 functional. In the context of pure TiO$_2$, the partial density of states (PDOS) reveals that the electronic band gap emerges between the O-2p and Ti-3d orbitals. It is suggested that the Ti-3d ($t_{2g}$) states play a more prominent role in bonding compared to the Ti-3d ($e_g$) states. We performed DFT calculations to investigate the impact of doping with other 3d transition metal atoms, leading to the emergence of impurity states within the band gap. The hybridization between the oxygen 2p orbitals and the titanium 3d orbitals in TiO$_2$ is altered by the introduction of doping with 3d transition metals because of the change in the oxidation state of titanium, shifting from solely 4+ to a combination of 4+ and 3+ states. The calculation of spin-polarized density demonstrates the emergence of ferromagnetic properties, particularly in titanium dioxide doped with chromium (Cr), manganese (Mn), and iron (Fe) with large magnetic moments. Our work demonstrates the significant impact of doping transition metals on TiO$_2$, allowing for the precise manipulation of electrical and magnetic properties, and thus holds great potential for the development of spin-based memory devices with possible neuromorphic applications.

### [Current-induced magnetization control in dipolar-coupled nanomagnet pairs and artificial spin ice](http://arxiv.org/abs/2601.16633v1)
**2026-01-23** | *A. Pac, G. M. Macauley, J. A. Brock et al.*

> Exploiting current-induced spin-orbit torques (SOTs) to manipulate the magnetic state of dipolar-coupled nanomagnet systems with in-plane magnetic anisotropy, such as artificial spin ices, provides a route to local, electrically-programmable control of the magnetization, with relevance for applications including neuromorphic computing. Here, we demonstrate how the orientation of a nanomagnet relative to the direction of an applied electrical current impacts the threshold current density needed for all-electrical magnetization switching, and how dipolar coupling between the nanomagnets influences the switching of interacting pairs and ensembles of nanomagnets. Using a material system designed to generate SOTs in response to electrical currents, we find that the current required to switch the magnetization of isolated nanomagnets varies non-monotonically as the angle between the nanomagnet long axis and the current increases. In small artificial spin ice systems, we observe similar angular dependence of the switching current, which can be used to control the magnetization orientation of specific subsets of nanomagnets. These experimental results are supported by micromagnetic modeling, which illustrates how the various current induced torques can be exploited to control magnetization switching in nanomagnetic systems. These results establish SOT switching as a practical method for programmable manipulation of dipolar nanomagnetic systems.

### [Emerging Threats and Countermeasures in Neuromorphic Systems: A Survey](http://arxiv.org/abs/2601.16589v1)
**2026-01-23** | *Pablo Sorrentino, Stjepan Picek, Ihsen Alouani et al.*

> Neuromorphic computing mimics brain-inspired mechanisms through spiking neurons and energy-efficient processing, offering a pathway to efficient in-memory computing (IMC). However, these advancements raise critical security and privacy concerns. As the adoption of bio-inspired architectures and memristive devices increases, so does the urgency to assess the vulnerability of these emerging technologies to hardware and software attacks. Emerging architectures introduce new attack surfaces, particularly due to asynchronous, event-driven processing and stochastic device behavior. The integration of memristors into neuromorphic hardware and software implementations in spiking neural networks offers diverse possibilities for advanced computing architectures, including their role in security-aware applications. This survey systematically analyzes the security landscape of neuromorphic systems, covering attack methodologies, side-channel vulnerabilities, and countermeasures. We focus on both hardware and software concerns relevant to spiking neural networks (SNNs) and hardware primitives, such as Physical Unclonable Functions (PUFs) and True Random Number Generators (TRNGs) for cryptographic and secure computation applications. We approach this analysis from diverse perspectives, from attack methodologies to countermeasure strategies that integrate efficiency and protection in brain-inspired hardware. This review not only maps the current landscape of security threats but provides a foundation for developing secure and trustworthy neuromorphic architectures.

### [A Case for Hypergraphs to Model and Map SNNs on Neuromorphic Hardware](http://arxiv.org/abs/2601.16118v1)
**2026-01-22** | *Marco Ronzani, Cristina Silvano*

> Executing Spiking Neural Networks (SNNs) on neuromorphic hardware poses the problem of mapping neurons to cores. SNNs operate by propagating spikes between neurons that form a graph through synapses. Neuromorphic hardware mimics them through a network-on-chip, transmitting spikes, and a mesh of cores, each managing several neurons. Its operational cost is tied to spike movement and active cores. A mapping comprises two tasks: partitioning the SNN's graph to fit inside cores and placement of each partition on the hardware mesh. Both are NP-hard problems, and as SNNs and hardware scale towards billions of neurons, they become increasingly difficult to tackle effectively. In this work, we propose to raise the abstraction of SNNs from graphs to hypergraphs, redesigning mapping techniques accordingly. The resulting model faithfully captures the replication of spikes inside cores by exposing the notion of hyperedge co-membership between neurons. We further show that the overlap and locality of hyperedges strongly correlate with high-quality mappings, making these properties instrumental in devising mapping algorithms. By exploiting them directly, grouping neurons through shared hyperedges, communication traffic and hardware resource usage can be reduced be yond what just contracting individual connections attains. To substantiate this insight, we consider several partitioning and placement algorithms, some newly devised, others adapted from literature, and compare them over progressively larger and bio-plausible SNNs. Our results show that hypergraph based techniques can achieve better mappings than the state-of-the-art at several execution time regimes. Based on these observations, we identify a promising selection of algorithms to achieve effective mappings at any scale.

### [CVD grown bilayer MoS2 based artificial optoelectronic synapses for arithmetic computing and image recognition applications](http://arxiv.org/abs/2601.15917v1)
**2026-01-22** | *Umakanta Patra, Subhrajit Sikdar, Roshan Padhan et al.*

> Demand for lower computing power has rapidly increased. In this context, brain-inspired neuromorphic computing, which integrate data storage and processing, has attracted significant attention. Here, our study reveals that field effect transistors fabricated on chemical vapor deposited bilayer (2L) MoS2 films can mimic the functions of biological synapse. These devices demonstrate high level of pair pulse facilitation (PPF), short term to long term memory (STM-to-LTM) transition as well as learning-forgetting-relearning properties. Effect of light intensity, pulse number, pulse width and photon energy on the STM-to-LTM transition is studied. It has been found that the rate of depression of the memory state can be controlled using the gate bias. Electrical and optical energy consumptions per synaptic event are estimated to be as low as 280 fJ and 20 nJ, respectively. Furthermore, photocurrent in these devices is observed to increase linearly with the number of the excitation pulses. This property has been exploited to demonstrate different arithmetic operations by the device. Moreover, these devices show great potential for image recognition. Artificial neural network simulation has returned an image recognition accuracy of ~85%. All these findings show a great prospect of 2L-MoS2 for developing low power, transparent and flexible neuromorphic devices.

### [Energy-efficient time series processing in real-time with fluidic iontronic memristor circuits](http://arxiv.org/abs/2601.14986v1)
**2026-01-21** | *T. M. Kamsma, Y. Gu, C. Spitoni et al.*

> Iontronic neuromorphic computing has emerged as a rapidly expanding paradigm. The arrival of angstrom-confined iontronic devices enables ultra-low power consumption with dynamics and memory timescales that intrinsically align well with signals of natural origin, a challenging combination for conventional (solid-state) neuromorphic materials. However, comparisons to earlier conventional substrates and evaluations of concrete application domains remain a challenge for iontronics. Here we propose a pathway toward iontronic circuits that can address established time series benchmark tasks, enabling performance comparisons and highlighting possible application domains for efficient real-time time series processing. We model a Kirchhoff-governed circuit with iontronic memristors as edges, while the dynamic internal voltages serve as output vector for a linear readout function, during which energy consumption is also logged. All these aspects are integrated into the open-source pyontronics package. Without requiring input encoding or virtual timing mechanisms, our simulations demonstrate prediction performance comparable to various earlier solid-state reservoirs, notably with an exceptionally low energy consumption of over 5 orders of magnitude lower. These results suggest a pathway of iontronic technologies for ultra-low-power real-time neuromorphic computation.

### [An Ion-Intercalation Memristor for Enabling Full Parallel Writing in Crossbar Networks](http://arxiv.org/abs/2601.14613v2)
**2026-01-21** | *Tingwei Zhang, Jiahui Liu, David Allstot et al.*

> Crossbar architectures have long been seen as a promising foundation for in-memory computing, using memristor arrays for high-density, energy-efficient analog computation. However, this conventional architecture suffers from a fundamental limitation: the inability to perform parallel write operations due to the sneak path problem. This arises from the structural overlap of read and write paths, forcing sequential or semi-parallel updates and severely limiting scalability. To address this, we introduce a new memristor design that decouples read and write operations at the device level. This design enables orthogonal conductive paths, and employs a reversible ion doping mechanism, inspired by lithium-ion battery principles, to modulate resistance states independently of computation. Fabricated devices exhibit near-ideal memristive characteristics and stable performance under isolated read/write conditions.

### [Polychronous Wave Computing: Timing-Native Address Selection in Spiking Networks](http://arxiv.org/abs/2601.13079v1)
**2026-01-19** | *Natalila G. Berloff*

> Spike timing offers a combinatorial address space, suggesting that timing-based spiking inference can be executed as lookup and routing rather than as dense multiply--accumulate. Yet most neuromorphic and photonic systems still digitize events into timestamps, bins, or rates and then perform selection in clocked logic. We introduce Polychronous Wave Computing (PWC), a timing-native address-selection primitive that maps relative spike latencies directly to a discrete output route in the wave domain. Spike times are phase-encoded in a rotating frame and processed by a programmable multiport interferometer that evaluates K template correlations in parallel; a driven--dissipative winner-take-all stage then performs a physical argmax, emitting a one-hot output port. We derive the operating envelope imposed by phase wrapping and mutual coherence, and collapse timing jitter, static phase mismatch, and dephasing into a single effective phase-noise budget whose induced winner--runner-up margin predicts boundary-first failures and provides an intensity-only calibration target. Simulations show that nonlinear competition improves routing fidelity compared with noisy linear intensity readout, and that hardware-in-the-loop phase tuning rescues a temporal-order gate from 55.9% to 97.2% accuracy under strong static mismatch. PWC provides a fast routing coprocessor for LUT-style spiking networks and sparse top-1 gates (e.g., mixture-of-experts routing) across polaritonic, photonic, and oscillator platforms.

### [Biological Intuition on Digital Hardware: An RTL Implementation of Poisson-Encoded SNNs for Static Image Classification](http://arxiv.org/abs/2601.12156v1)
**2026-01-17** | *Debabrata Das, Yogeeth G. K., Arnav Gupta*

> The deployment of Artificial Intelligence on edge devices (TinyML) is often constrained by the high power consumption and latency associated with traditional Artificial Neural Networks (ANNs) and their reliance on intensive Matrix-Multiply (MAC) operations. Neuromorphic computing offers a compelling alternative by mimicking biological efficiency through event-driven processing. This paper presents the design and implementation of a cycle-accurate, hardware-oriented Spiking Neural Network (SNN) core implemented in SystemVerilog. Unlike conventional accelerators, this design utilizes a Leaky Integrate-and-Fire (LIF) neuron model powered by fixed-point arithmetic and bit-wise primitives (shifts and additions) to eliminate the need for complex floating-point hardware. The architecture features an on-chip Poisson encoder for stochastic spike generation and a novel active pruning mechanism that dynamically disables neurons post-classification to minimize dynamic power consumption. We demonstrate the hardware's efficacy through a fully connected layer implementation targeting digit classification. Simulation results indicate that the design achieves rapid convergence (89% accuracy) within limited timesteps while maintaining a significantly reduced computational footprint compared to traditional dense architectures. This work serves as a foundational building block for scalable, energy-efficient neuromorphic hardware on FPGA and ASIC platforms.

### [Integrated nano electro-optomechanical spiking neuron](http://arxiv.org/abs/2601.11857v1)
**2026-01-17** | *Gregorio Beltramo, RÃ³bert HorvÃ¡th, GrÃ©goire Beaudoin et al.*

> Neuromorphic computing offers a pathway toward energy-efficient processing of data, yet hardware platforms combining nanoscale integration and multimodal functionality remain scarce. Here we demonstrate a gallium-phosphide electro-optomechanical spiking neuron that integrates optical and electromechanical interfaces within a single nanostructure on a silicon photonic chip operating at telecommunication wavelengths (1550 nm) and exploiting a 3 gigahertz-frequency mechanical mode. Our device displays excitable dynamics, generating optical spikes at its output, as in the spiking activity of neurons and cardiac cells and defined by the calibrated all-or-none response to external perturbations. This dynamic is consistent with the saddle-node on invariant circle scenario and associated features are demonstrated including control of excitable threshold, temporal summation and refractory period. Our device compact footprint and its CMOS-compatible platform make it well suited for edge-computing applications requiring low latency and establish a foundation for versatile brain-inspired optomechanical computing and advanced on-chip optical pulse sources.

### [Effects of Integrated Heatsinking on Superconductivity in Tantalum Nitride Nanowires at the 300 Millimeter Scale](http://arxiv.org/abs/2601.10480v1)
**2026-01-15** | *Ekta Bhatia, Tharanga R. Nanayakkara, Chenyu Zhou et al.*

> We report the superconducting properties of tantalum nitride (TaN) nanowires and TaN/copper (TaN/Cu) bilayer nanowires fabricated on 300 mm silicon wafers using CMOS-compatible processes. We evaluate how an integrated Cu heatsink modifies the superconducting response of TaN nanowires by improving thermal dissipation without significantly compromising key superconducting parameters. Through analysis of hysteresis in current-voltage curves, we demonstrate that Cu integration improves heat dissipation, supporting expectations of faster reset times in superconducting nanowire single-photon detectors (SNSPDs), consistent with enhanced heat transfer away from the hot spot. Using the Skocpol-Beasley-Tinkham (SBT) hotspot model, we quantify the Cu-enabled improvement in heat transfer as an approximately 100x increase in the SBT slope parameter beta and effective interfacial heat-transfer efficiency compared to TaN nanowires. The near-unity ratio of critical to retrapping current in TaN/Cu bilayer nanowires provides another evidence of efficient heat removal enabled by the integrated Cu layer. Our results show a zero-temperature Ginzburg-Landau coherence length of 7 nm and a critical temperature of 4.1 K for 39 nm thick TaN nanowires. The nanowires show <5% variation in critical dimensions, room-temperature resistance, residual resistance ratio, critical temperature, and critical current across the 300 mm wafer for all measured linewidths, demonstrating excellent process uniformity and scalability. These results indicate the trade-offs between superconducting performance and heat-sinking efficiency in TaN/Cu bilayer nanowires. They also underscore the viability of wafer-scale fabrication for fast, large-area SNSPD arrays for applications in photonic quantum computing, cosmology, and neuromorphic computing devices.

### [Bridging Superconducting and Neutral-Atom Platforms for Efficient Fault-Tolerant Quantum Architectures](http://arxiv.org/abs/2601.10144v1)
**2026-01-15** | *Xiang Fang, Jixuan Ruan, Sharanya Prabhu et al.*

> The transition to the fault-tolerant era exposes the limitations of homogeneous quantum systems, where no single qubit modality simultaneously offers optimal operation speed, connectivity, and scalability. In this work, we propose a strategic approach to Heterogeneous Quantum Architectures (HQA) that synthesizes the distinct advantages of the superconducting (SC) and neutral atom (NA) platforms. We explore two architectural role assignment strategies based on hardware characteristics: (1) We offload the latency-critical Magic State Factory (MSF) to fast SC devices while performing computation on scalable NA arrays, a design we term MagicAcc, which effectively mitigates the resource-preparation bottleneck. (2) We explore a Memory-Compute Separation (MCSep) paradigm that utilizes NA arrays for high-density qLDPC memory storage and SC devices for fast surface-code processing. Our evaluation, based on a comprehensive end-to-end cost model, demonstrates that principled heterogeneity yields significant performance gains. Specifically, our designs achieve $752\times$ speedup over NA-only baselines on average and reduce the physical qubit footprint by over $10\times$ compared to SC-only systems. These results chart a clear pathway for leveraging cross-modality interconnects to optimize the space-time efficiency of future fault-tolerant quantum computers.

### [Resistive Memory based Efficient Machine Unlearning and Continual Learning](http://arxiv.org/abs/2601.10037v1)
**2026-01-15** | *Ning Lin, Jichang Yang, Yangu He et al.*

> Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge.

### [A Compute and Communication Runtime Model for Loihi 2](http://arxiv.org/abs/2601.10035v1)
**2026-01-15** | *Jonathan Timcheck, Alessandro Pierro, Sumit Bam Shrestha*

> Neuromorphic computers hold the potential to vastly improve the speed and efficiency of a wide range of computational kernels with their asynchronous, compute-memory co-located, spatially distributed, and scalable nature. However, performance models that are simple yet sufficiently expressive to predict runtime on actual neuromorphic hardware are lacking, posing a challenge for researchers and developers who strive to design fast algorithms and kernels. As breaking the memory bandwidth wall of conventional von-Neumann architectures is a primary neuromorphic advantage, modeling communication time is especially important. At the same time, modeling communication time is difficult, as complex congestion patterns arise in a heavily-loaded Network-on-Chip. In this work, we introduce the first max-affine lower-bound runtime model -- a multi-dimensional roofline model -- for Intel's Loihi 2 neuromorphic chip that quantitatively accounts for both compute and communication based on a suite of microbenchmarks. Despite being a lower-bound model, we observe a tight correspondence (Pearson correlation coefficient greater than or equal to 0.97) between our model's estimated runtime and the measured runtime on Loihi 2 for a neural network linear layer, i.e., matrix-vector multiplication, and for an example application, a Quadratic Unconstrained Binary Optimization solver. Furthermore, we derive analytical expressions for communication-bottlenecked runtime to study scalability of the linear layer, revealing an area-runtime tradeoff for different spatial workload configurations with linear to superliner runtime scaling in layer size with a variety of constant factors. Our max-affine runtime model helps empower the design of high-speed algorithms and kernels for Loihi 2.

### [Forward-only learning in memristor arrays with month-scale stability](http://arxiv.org/abs/2601.09903v1)
**2026-01-14** | *Adrien Renaudineau, Mamadou Hawa Diallo, ThÃ©o Dupuis et al.*

> Turning memristor arrays from efficient inference engines into systems capable of on-chip learning has proved difficult. Weight updates have a high energy cost and cause device wear, analog states drift, and backpropagation requires a backward pass with reversed signal flow. Here we experimentally demonstrate learning on standard filamentary HfOx/Ti arrays that addresses these challenges with two design choices. First, we realize that standard filamentary HfOx/Ti memristors support sub-1 V reset-only pulses that cut energy, improve endurance, and yield stable analog states. Second, we rely on forward-only training algorithms derived from Hinton's Forward-Forward that use only inference-style operations. We train two-layer classifiers on an ImageNet-resolution four-class task using arrays up to 8,064 devices. Two forward-only variants, the double-pass supervised Forward-Forward and a single-pass competitive rule, achieve test accuracies of 89.5% and 89.6%, respectively; a reference experiment using backpropagation reaches 90.0%. Across five independent runs per method, these accuracies match within statistical uncertainty. Trained models retain accuracy for at least one month under ambient conditions, consistent with the stability of reset-only states. Sub-1 V reset updates use 460 times less energy than conventional program-and-verify programming and require just 46% more energy than inference-only operation. Together, these results establish forward-only, sub-1 V learning on standard filamentary stacks at array scale, outlining a practical, pulse-aware route to adaptive edge intelligence.

### [Criticality in memristor devices and the creation of deep memory](http://arxiv.org/abs/2601.09464v1)
**2026-01-14** | *Stavros G. Stavrinides, Yiannis Contoyiannis*

> In the present work we describe a way to assess memory capability of real devices, while proposing to the engineering community what to pursue to create devices with deep associated memory capability. The study of the signal produced by a real memristor nano-device focused on the description in terms of the Landau Ï†4 theory for the critical phenomena in finite systems. This further allowed the utilization of the property of the anomalous enhancement of the autocorrelation function when a system is on the Spontaneous Symmetry Breaking (SSB), for improving the quantity of the demonstrated memory, while simultaneously maintaining a very good quality, as this is expressed by the stability of the autocorrelation function. In this proof-of-concept case, the morphology of the signal allowed us to impose the appropriate modifications on the signal so that we finally show how to get very close to the characteristics of the SSB and thus achieve our goal to get as close as possible to the ideal behavior of a Memristor that yields deep memory. Finally, we provide proof of the stability of memristor's operation by showing that solitons "follow" as a skeleton structure the experimentally derived time series.

### [Dynamical stability by spin transfer in nearly isotropic magnets](http://arxiv.org/abs/2601.08738v1)
**2026-01-13** | *Hidekazu Kurebayashi, Joseph Barker, Takumi Yamazaki et al.*

> Spin transfer torques (STTs) control magnetisation by electric currents, enabling a range of nano-scale spintronic applications. They can destabilise the equilibrium magnetisation state by counteracting magnetic relaxation. Here, we maximise the STT effect through a dedicated growth-annealing protocol for CoFeB thin films, such that magnetic anisotropies originating from the interface and shape almost cancel each other. The nearly isotropic magnets enable low-current dynamical stabilisation of the magnetisation in the direction opposite to an applied magnetic field, thereby realising a spintronic analogue of the Kapitza pendulum. In an intermediate current regime, the STT drives large magnetisation vector fluctuations that cover the entire Bloch sphere. The continuous variable associated with the stochastic magnetisation direction may serve as a resource for probabilistic computing and neuromorphic hardware. Our results establish isotropic magnets as a platform to study as-yet-uncharted, far-from-equilibrium spin dynamics including anti-magnonics, with promising implications for unconventional computing paradigms.

---

## ðŸ§  Algorithms & Theory

### [Reliable Brain Tumor Segmentation Based on Spiking Neural Networks with Efficient Training](http://arxiv.org/abs/2601.16652v1)
**2026-01-23** | *Aurora Pia Ghiardelli, Guangzhi Tang, Tao Sun*

> We propose a reliable and energy-efficient framework for 3D brain tumor segmentation using spiking neural networks (SNNs). A multi-view ensemble of sagittal, coronal, and axial SNN models provides voxel-wise uncertainty estimation and enhances segmentation robustness. To address the high computational cost in training SNN models for semantic image segmentation, we employ Forward Propagation Through Time (FPTT), which maintains temporal learning efficiency with significantly reduced computational cost. Experiments on the Multimodal Brain Tumor Segmentation Challenges (BraTS 2017 and BraTS 2023) demonstrate competitive accuracy, well-calibrated uncertainty, and an 87% reduction in FLOPs, underscoring the potential of SNNs for reliable, low-power medical IoT and Point-of-Care systems.

### [Spiking Neural Networks for Communication Systems: Encoding Schemes, Learning Algorithms, and Equalization~Techniques](http://arxiv.org/abs/2601.16550v1)
**2026-01-23** | *Eike-Manuel Edelmann*

> Machine learning with artificial neural networks (ANNs), provides solutions for the growing complexity of modern communication systems. This complexity, however, increases power consumption, making the systems energy-intensive. Spiking neural networks (SNNs) represent a novel generation of neural networks inspired by the highly efficient human brain. By emulating its event-driven and energy-efficient mechanisms, SNNs enable low-power, real-time signal processing. They differ from ANNs in two key ways: they exhibit inherent temporal dynamics and process and transmit information as short binary signals called spikes. Despite their promise, major challenges remain, e.g., identifying optimal learning rules and effective neural encoding. This thesis investigates the design of SNN-based receivers for nonlinear time-invariant frequency-selective channels. Backpropagation through time with surrogate gradients is identified as a promising update rule and the novel quantization encoding (QE) as promising neural encoding. Given the model of the intensity modulation with direct detection link, we compare two different receiver architectures based on equalization performance and spike count. Using decision feedback and QE achieves both strong performance and low spike counts. Notably, SNN-based receivers significantly outperform ANN-based counterparts. We furthermore introduce policy gradient-based update (PGU), an reinforcement learning-based update algorithm that requires no backpropagation. Using PGU, encoding parameters are optimized, drastically reducing runtime, complexity, and spikes per inference while maintaining performance. This thesis contributes a successful design and optimization framework for SNN-based receivers. By addressing key challenges in SNN optimization, it facilitates future advances in the design and deployment of energy-efficient SNN receivers.

### [Ternary Spiking Neural Networks Enhanced by Complemented Neurons and Membrane Potential Aggregation](http://arxiv.org/abs/2601.15598v1)
**2026-01-22** | *Boxuan Zhang, Jiaxin Wang, Zhen Xu et al.*

> Spiking Neural Networks (SNNs) are promising energy-efficient models and powerful framworks of modeling neuron dynamics. However, existing binary spiking neurons exhibit limited biological plausibilities and low information capacity. Recently developed ternary spiking neuron possesses higher consistency with biological principles (i.e. excitation-inhibition balance mechanism). Despite of this, the ternary spiking neuron suffers from defects including iterative information loss, temporal gradient vanishing and irregular distributions of membrane potentials. To address these issues, we propose Complemented Ternary Spiking Neuron (CTSN), a novel ternary spiking neuron model that incorporates an learnable complemental term to store information from historical inputs. CTSN effectively improves the deficiencies of ternary spiking neuron, while the embedded learnable factors enable CTSN to adaptively adjust neuron dynamics, providing strong neural heterogeneity. Furthermore, based on the temporal evolution features of ternary spiking neurons' membrane potential distributions, we propose the Temporal Membrane Potential Regularization (TMPR) training method. TMPR introduces time-varying regularization strategy utilizing membrane potentials, furhter enhancing the training process by creating extra backpropagation paths. We validate our methods through extensive experiments on various datasets, demonstrating remarkable performance advances.

### [Power-Law Scaling in the Classification Performance of Small-Scale Spiking Neural Networks](http://arxiv.org/abs/2601.14961v1)
**2026-01-21** | *Zhengdi Zhang, Cong Han, Wenjun Xia*

> This paper investigates the classification capability of small-scale spiking neural networks based on the Leaky Integrate-and-Fire (LIF) neuron model. We analyze the relationship between classification accuracy and three factors: the number of neurons, the number of stimulus nodes, and the number of classification categories. Notably, we employ a large language model (LLM) to assist in discovering the underlying functional relationships among these variables, and compare its performance against traditional methods such as linear and polynomial fitting. Experimental results show that classification accuracy follows a power-law scaling primarily with the number of categories, while the effects of neuron count and stimulus nodes are relatively minor. A key advantage of the LLM-based approach is its ability to propose plausible functional forms beyond pre-defined equation templates, often leading to more concise or accurate mathematical descriptions of the observed scaling laws. This finding has important implications for understanding efficient computation in biological neural systems and for pioneering new paradigms in AI-aided scientific discovery.

### [Effects of Introducing Synaptic Scaling on Spiking Neural Network Learning](http://arxiv.org/abs/2601.11261v1)
**2026-01-16** | *Shinnosuke Touda, Hirotsugu Okuno*

> Spiking neural networks (SNNs) employing unsupervised learning methods inspired by neural plasticity are expected to be a new framework for artificial intelligence. In this study, we investigated the effect of multiple types of neural plasticity, such as spike-time-dependent plasticity (STDP) and synaptic scaling, on the learning in a winner-take-all (WTA) network composed of spiking neurons. We implemented a WTA network with multiple types of neural plasticity using Python. The MNIST and the Fashion-MNIST datasets were used for training and testing. We varied the number of neurons, the time constant of STDP, and the normalization method used in synaptic scaling to compare classification accuracy. The results demonstrated that synaptic scaling based on the L2 norm was the most effective in improving classification performance. By implementing L2-norm-based synaptic scaling and setting the number of neurons in both excitatory and inhibitory layers to 400, the network achieved classification accuracies of 88.84 % on the MNIST dataset and 68.01 % on the Fashion-MNIST dataset after one epoch of training.

### [Supervised Spike Agreement Dependent Plasticity for Fast Local Learning in Spiking Neural Networks](http://arxiv.org/abs/2601.08526v1)
**2026-01-13** | *Gouri Lakshmi S, Athira Chandrasekharan, Harshit Kumar et al.*

> Spike-Timing-Dependent Plasticity (STDP) provides a biologically grounded learning rule for spiking neural networks (SNNs), but its reliance on precise spike timing and pairwise updates limits fast learning of weights. We introduce a supervised extension of Spike Agreement-Dependent Plasticity (SADP), which replaces pairwise spike-timing comparisons with population-level agreement metrics such as Cohen's kappa. The proposed learning rule preserves strict synaptic locality, admits linear-time complexity, and enables efficient supervised learning without backpropagation, surrogate gradients, or teacher forcing.   We integrate supervised SADP within hybrid CNN-SNN architectures, where convolutional encoders provide compact feature representations that are converted into Poisson spike trains for agreement-driven learning in the SNN. Extensive experiments on MNIST, Fashion-MNIST, CIFAR-10, and biomedical image classification tasks demonstrate competitive performance and fast convergence. Additional analyses show stable performance across broad hyperparameter ranges and compatibility with device-inspired synaptic update dynamics. Together, these results establish supervised SADP as a scalable, biologically grounded, and hardware-aligned learning paradigm for spiking neural networks.

---

## ðŸ‘ï¸ Applications & Sensing

### [A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control](http://arxiv.org/abs/2601.14628v1)
**2026-01-21** | *Weiyu Guo, He Zhang, Pengteng Li et al.*

> Recent advances in embodied intelligence have leveraged massive scaling of data and model parameters to master natural-language command following and multi-task control. In contrast, biological systems demonstrate an innate ability to acquire skills rapidly from sparse experience. Crucially, current robotic policies struggle to replicate the dynamic stability, reflexive responsiveness, and temporal memory inherent in biological motion. Here we present Neuromorphic Vision-Language-Action (NeuroVLA), a framework that mimics the structural organization of the bio-nervous system between the cortex, cerebellum, and spinal cord. We adopt a system-level bio-inspired design: a high-level model plans goals, an adaptive cerebellum module stabilizes motion using high-frequency sensors feedback, and a bio-inspired spinal layer executes lightning-fast actions generation. NeuroVLA represents the first deployment of a neuromorphic VLA on physical robotics, achieving state-of-the-art performance. We observe the emergence of biological motor characteristics without additional data or special guidance: it stops the shaking in robotic arms, saves significant energy(only 0.4w on Neuromorphic Processor), shows temporal memory ability and triggers safety reflexes in less than 20 milliseconds.

### [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](http://arxiv.org/abs/2601.13498v1)
**2026-01-20** | *Nimrod Kruger, Nicholas Owen Ralph, Gregory Cohen et al.*

> Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

### [Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization](http://arxiv.org/abs/2601.13451v1)
**2026-01-19** | *Reza Ahmadvand, Sarah Safura Sharif, Yaser Mike Banad*

> This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.

### [Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints](http://arxiv.org/abs/2601.13252v1)
**2026-01-19** | *Mahmud S. Zango, Jianglin Lan*

> Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging "Edge AI" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the "Sim-to-Real" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments.

### [UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow](http://arxiv.org/abs/2601.10054v1)
**2026-01-15** | *Nick Truong, Pritam P. Karmokar, William J. Beksi*

> Underwater imaging is fundamentally challenging due to wavelength-dependent light attenuation, strong scattering from suspended particles, turbidity-induced blur, and non-uniform illumination. These effects impair standard cameras and make ground-truth motion nearly impossible to obtain. On the other hand, event cameras offer microsecond resolution and high dynamic range. Nonetheless, progress on investigating event cameras for underwater environments has been limited due to the lack of datasets that pair realistic underwater optics with accurate optical flow. To address this problem, we introduce the first synthetic underwater benchmark dataset for event-based optical flow derived from physically-based ray-traced RGBD sequences. Using a modern video-to-event pipeline applied to rendered underwater videos, we produce realistic event data streams with dense ground-truth flow, depth, and camera motion. Moreover, we benchmark state-of-the-art learning-based and model-based optical flow prediction methods to understand how underwater light transport affects event formation and motion estimation accuracy. Our dataset establishes a new baseline for future development and evaluation of underwater event-based perception algorithms. The source code and dataset for this project are publicly available at https://robotic-vision-lab.github.io/ueof.

### [Hybrid guided variational autoencoder for visual place recognition](http://arxiv.org/abs/2601.09248v1)
**2026-01-14** | *Ni Wang, Zihan You, Emre Neftci et al.*

> Autonomous agents such as cars, robots and drones need to precisely localize themselves in diverse environments, including in GPS-denied indoor environments. One approach for precise localization is visual place recognition (VPR), which estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of our model is based on a spiking neural network model which is compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in our new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while, showing robust performance also under various illumination conditions. When tested with novel visual inputs from unknown scenes, our model can distinguish between these places, which demonstrates a high generalization capability by learning the essential features of location. Our compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.

---

## ðŸ“‚ General / Uncategorized

### [Annotated PIM Bibliography](http://arxiv.org/abs/2601.09002v1)
**2026-01-13** | *Peter M. Kogge*

> Processing in Memory (PIM) and similar terms such as Compute In Memory (CIM), Logic in Memory (LIM), In Memory Computing (IMC), and Near Memory Computing (NMC) have gained attention recently as a potentially ``revolutionary new'' technique. The truth, however, is that many examples of the technology go back over 60 years. This document attempts to provide an annotated bibliography of PIM technology that attempts to cover the whole time-frame, and is organized to augment a forth-coming article.

---

