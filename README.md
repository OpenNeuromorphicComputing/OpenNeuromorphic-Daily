# ðŸ§  Open Neuromorphic - Daily ArXiv

**Automated Daily Update** | Last Run: 2026-01-16 08:29 UTC

Papers are automatically categorized by topic and sorted by date.

## ðŸ›  Hardware & Materials

### [Effects of Integrated Heatsinking on Superconductivity in Tantalum Nitride Nanowires at the 300 Millimeter Scale](http://arxiv.org/abs/2601.10480v1)
**2026-01-15** | *Ekta Bhatia, Tharanga R. Nanayakkara, Chenyu Zhou et al.*

> We report the superconducting properties of tantalum nitride (TaN) nanowires and TaN/copper (TaN/Cu) bilayer nanowires fabricated on 300 mm silicon wafers using CMOS-compatible processes. We evaluate how an integrated Cu heatsink modifies the superconducting response of TaN nanowires by improving thermal dissipation without significantly compromising key superconducting parameters. Through analysis of hysteresis in current-voltage curves, we demonstrate that Cu integration improves heat dissipation, supporting expectations of faster reset times in superconducting nanowire single-photon detectors (SNSPDs), consistent with enhanced heat transfer away from the hot spot. Using the Skocpol-Beasley-Tinkham (SBT) hotspot model, we quantify the Cu-enabled improvement in heat transfer as an approximately 100x increase in the SBT slope parameter beta and effective interfacial heat-transfer efficiency compared to TaN nanowires. The near-unity ratio of critical to retrapping current in TaN/Cu bilayer nanowires provides another evidence of efficient heat removal enabled by the integrated Cu layer. Our results show a zero-temperature Ginzburg-Landau coherence length of 7 nm and a critical temperature of 4.1 K for 39 nm thick TaN nanowires. The nanowires show <5% variation in critical dimensions, room-temperature resistance, residual resistance ratio, critical temperature, and critical current across the 300 mm wafer for all measured linewidths, demonstrating excellent process uniformity and scalability. These results indicate the trade-offs between superconducting performance and heat-sinking efficiency in TaN/Cu bilayer nanowires. They also underscore the viability of wafer-scale fabrication for fast, large-area SNSPD arrays for applications in photonic quantum computing, cosmology, and neuromorphic computing devices.

### [Bridging Superconducting and Neutral-Atom Platforms for Efficient Fault-Tolerant Quantum Architectures](http://arxiv.org/abs/2601.10144v1)
**2026-01-15** | *Xiang Fang, Jixuan Ruan, Sharanya Prabhu et al.*

> The transition to the fault-tolerant era exposes the limitations of homogeneous quantum systems, where no single qubit modality simultaneously offers optimal operation speed, connectivity, and scalability. In this work, we propose a strategic approach to Heterogeneous Quantum Architectures (HQA) that synthesizes the distinct advantages of the superconducting (SC) and neutral atom (NA) platforms. We explore two architectural role assignment strategies based on hardware characteristics: (1) We offload the latency-critical Magic State Factory (MSF) to fast SC devices while performing computation on scalable NA arrays, a design we term MagicAcc, which effectively mitigates the resource-preparation bottleneck. (2) We explore a Memory-Compute Separation (MCSep) paradigm that utilizes NA arrays for high-density qLDPC memory storage and SC devices for fast surface-code processing. Our evaluation, based on a comprehensive end-to-end cost model, demonstrates that principled heterogeneity yields significant performance gains. Specifically, our designs achieve $752\times$ speedup over NA-only baselines on average and reduce the physical qubit footprint by over $10\times$ compared to SC-only systems. These results chart a clear pathway for leveraging cross-modality interconnects to optimize the space-time efficiency of future fault-tolerant quantum computers.

### [Resistive Memory based Efficient Machine Unlearning and Continual Learning](http://arxiv.org/abs/2601.10037v1)
**2026-01-15** | *Ning Lin, Jichang Yang, Yangu He et al.*

> Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge.

### [A Compute and Communication Runtime Model for Loihi 2](http://arxiv.org/abs/2601.10035v1)
**2026-01-15** | *Jonathan Timcheck, Alessandro Pierro, Sumit Bam Shrestha*

> Neuromorphic computers hold the potential to vastly improve the speed and efficiency of a wide range of computational kernels with their asynchronous, compute-memory co-located, spatially distributed, and scalable nature. However, performance models that are simple yet sufficiently expressive to predict runtime on actual neuromorphic hardware are lacking, posing a challenge for researchers and developers who strive to design fast algorithms and kernels. As breaking the memory bandwidth wall of conventional von-Neumann architectures is a primary neuromorphic advantage, modeling communication time is especially important. At the same time, modeling communication time is difficult, as complex congestion patterns arise in a heavily-loaded Network-on-Chip. In this work, we introduce the first max-affine lower-bound runtime model -- a multi-dimensional roofline model -- for Intel's Loihi 2 neuromorphic chip that quantitatively accounts for both compute and communication based on a suite of microbenchmarks. Despite being a lower-bound model, we observe a tight correspondence (Pearson correlation coefficient greater than or equal to 0.97) between our model's estimated runtime and the measured runtime on Loihi 2 for a neural network linear layer, i.e., matrix-vector multiplication, and for an example application, a Quadratic Unconstrained Binary Optimization solver. Furthermore, we derive analytical expressions for communication-bottlenecked runtime to study scalability of the linear layer, revealing an area-runtime tradeoff for different spatial workload configurations with linear to superliner runtime scaling in layer size with a variety of constant factors. Our max-affine runtime model helps empower the design of high-speed algorithms and kernels for Loihi 2.

### [Forward-only learning in memristor arrays with month-scale stability](http://arxiv.org/abs/2601.09903v1)
**2026-01-14** | *Adrien Renaudineau, Mamadou Hawa Diallo, ThÃ©o Dupuis et al.*

> Turning memristor arrays from efficient inference engines into systems capable of on-chip learning has proved difficult. Weight updates have a high energy cost and cause device wear, analog states drift, and backpropagation requires a backward pass with reversed signal flow. Here we experimentally demonstrate learning on standard filamentary HfOx/Ti arrays that addresses these challenges with two design choices. First, we realize that standard filamentary HfOx/Ti memristors support sub-1 V reset-only pulses that cut energy, improve endurance, and yield stable analog states. Second, we rely on forward-only training algorithms derived from Hinton's Forward-Forward that use only inference-style operations. We train two-layer classifiers on an ImageNet-resolution four-class task using arrays up to 8,064 devices. Two forward-only variants, the double-pass supervised Forward-Forward and a single-pass competitive rule, achieve test accuracies of 89.5% and 89.6%, respectively; a reference experiment using backpropagation reaches 90.0%. Across five independent runs per method, these accuracies match within statistical uncertainty. Trained models retain accuracy for at least one month under ambient conditions, consistent with the stability of reset-only states. Sub-1 V reset updates use 460 times less energy than conventional program-and-verify programming and require just 46% more energy than inference-only operation. Together, these results establish forward-only, sub-1 V learning on standard filamentary stacks at array scale, outlining a practical, pulse-aware route to adaptive edge intelligence.

### [Criticality in memristor devices and the creation of deep memory](http://arxiv.org/abs/2601.09464v1)
**2026-01-14** | *Stavros G. Stavrinides, Yiannis Contoyiannis*

> In the present work we describe a way to assess memory capability of real devices, while proposing to the engineering community what to pursue to create devices with deep associated memory capability. The study of the signal produced by a real memristor nano-device focused on the description in terms of the Landau Ï†4 theory for the critical phenomena in finite systems. This further allowed the utilization of the property of the anomalous enhancement of the autocorrelation function when a system is on the Spontaneous Symmetry Breaking (SSB), for improving the quantity of the demonstrated memory, while simultaneously maintaining a very good quality, as this is expressed by the stability of the autocorrelation function. In this proof-of-concept case, the morphology of the signal allowed us to impose the appropriate modifications on the signal so that we finally show how to get very close to the characteristics of the SSB and thus achieve our goal to get as close as possible to the ideal behavior of a Memristor that yields deep memory. Finally, we provide proof of the stability of memristor's operation by showing that solitons "follow" as a skeleton structure the experimentally derived time series.

### [Dynamical stability by spin transfer in nearly isotropic magnets](http://arxiv.org/abs/2601.08738v1)
**2026-01-13** | *Hidekazu Kurebayashi, Joseph Barker, Takumi Yamazaki et al.*

> Spin transfer torques (STTs) control magnetisation by electric currents, enabling a range of nano-scale spintronic applications. They can destabilise the equilibrium magnetisation state by counteracting magnetic relaxation. Here, we maximise the STT effect through a dedicated growth-annealing protocol for CoFeB thin films, such that magnetic anisotropies originating from the interface and shape almost cancel each other. The nearly isotropic magnets enable low-current dynamical stabilisation of the magnetisation in the direction opposite to an applied magnetic field, thereby realising a spintronic analogue of the Kapitza pendulum. In an intermediate current regime, the STT drives large magnetisation vector fluctuations that cover the entire Bloch sphere. The continuous variable associated with the stochastic magnetisation direction may serve as a resource for probabilistic computing and neuromorphic hardware. Our results establish isotropic magnets as a platform to study as-yet-uncharted, far-from-equilibrium spin dynamics including anti-magnonics, with promising implications for unconventional computing paradigms.

### [Neuromorphic FPGA Design for Digital Signal Processing](http://arxiv.org/abs/2601.07069v1)
**2026-01-11** | *Justin London*

> In this paper, the foundations of neuromorphic computing, spiking neural networks (SNNs) and memristors, are analyzed and discussed. Neuromorphic computing is then applied to FPGA design for digital signal processing (DSP). Finite impulse response (FIR) and infinite impulse response (IIR) filters are implemented with and without neuromorphic computing in Vivado using Verilog HDL. The results suggest that neuromorphic computing can provide low-latency and synaptic plasticity thereby enabling continuous on-chip learning. Due to their parallel and event-driven nature, neuromorphic computing can reduce power consumption by eliminating von Neumann bottlenecks and improve efficiency, but at the cost of reduced numeric precision.

### [Thermally Configurable Multi-Order Polar Skyrmions in Multiferroic Oxide Superlattices](http://arxiv.org/abs/2601.05950v1)
**2026-01-09** | *Kefan Liu, Yuhui Huang, Xiangwei Guo et al.*

> Polar topological textures in low-dimensional ferroelectrics have emerged as a versatile platform for high-density information storage and neuromorphic computing. While low-order topological states, such as vortices and skyrmions, have been extensively studied, high-order polar topological families remain largely unexplored due to their higher energy requirements and limited stabilization methods. Here, using a BiFeO3 (BFO)-based multiferroic superlattice as a model system, we demonstrate a thermal-modulation strategy that stabilizes multi-order polar skyrmions and enables reversible tuning of their topological order through phase-field simulations. It was found that temperature modulation drives the system from polar solitons through 1Ï€-, 2Ï€-, 3Ï€-, and 4Ï€-skyrmion states, with closed heating-cooling path analyses revealing the widest thermal stability window for 2Ï€-skyrmions (up to 600 K). Leveraging this robustness, 2% Sm doping in BFO lowers the transition temperatures, enabling room-temperature stabilization of 2Ï€-skyrmions. These findings enrich the fundamental understanding of multi-order polar topologies and establish a tunable strategy for realizing variable-order topological configurations in practical memory devices.

### [Self-Evolving Distributed Memory Architecture for Scalable AI Systems](http://arxiv.org/abs/2601.05569v1)
**2026-01-09** | *Zixuan Li, Chuanzhen Wang, Haotian Sun*

> Distributed AI systems face critical memory management challenges across computation, communication, and deployment layers. RRAM based in memory computing suffers from scalability limitations due to device non idealities and fixed array sizes. Decentralized AI frameworks struggle with memory efficiency across NAT constrained networks due to static routing that ignores computational load. Multi agent deployment systems tightly couple application logic with execution environments, preventing adaptive memory optimization. These challenges stem from a fundamental lack of coordinated memory management across architectural layers. We introduce Self Evolving Distributed Memory Architecture for Scalable AI Systems, a three layer framework that unifies memory management across computation, communication, and deployment. Our approach features (1) memory guided matrix processing with dynamic partitioning based on device characteristics, (2) memory aware peer selection considering network topology and computational capacity, and (3) runtime adaptive deployment optimization through continuous reconfiguration. The framework maintains dual memory systems tracking both long term performance patterns and short term workload statistics. Experiments on COCO 2017, ImageNet, and SQuAD show that our method achieves 87.3 percent memory utilization efficiency and 142.5 operations per second compared to Ray Distributed at 72.1 percent and 98.7 operations per second, while reducing communication latency by 30.2 percent to 171.2 milliseconds and improving resource utilization to 82.7 percent. Our contributions include coordinated memory management across three architectural layers, workload adaptive resource allocation, and a dual memory architecture enabling dynamic system optimization.

### [Local Multimodal Dynamics in Mixed Ionic-Electronic Conductors and Their Fingerprints in Organic Electrochemical Transistor Operation](http://arxiv.org/abs/2601.05179v1)
**2026-01-08** | *Shubham Tanwar, Han-Yan Wu, Chi-Yuan Yang et al.*

> Mixed ionic-electronic conductors host tightly coupled interactions among mobile ions, electronic charges, and the polymer matrix, giving rise to complex multimodal responses spanning electrical, mechanical, and morphological transformations. These materials underpin organic electrochemical transistors (OECTs), which translate such interactions into low-voltage signal amplification and sensing for applications in bioelectronics, neuromorphic computing, and memory. Despite their central role, OECT current-voltage transfer characteristics are often treated phenomenologically, as both the local multimodal dynamics and their connection to global device response remain unresolved. Here, we reveal that the transfer curve encodes a cascade of spatially localized electrochemical transitions, each associated with distinct changes in conductivity, stiffness, and morphology, fundamentally redefining it as a spatially resolved fingerprint of device's internal state. Using automated operando multimodal in-liquid scanning dielectric microscopy, we directly map these dynamics and identify region-specific electrochemical thresholds governing the interplay between source, channel, and drain. We found that the local tip-sample electrostatic force serves as a remarkable mechanistic observable of coupled multimodal dynamics in mixed conductors. A physically grounded model links it to general material, interfacial, and geometric parameters, enabling mechanistic interpretation and predictive insights. Our work provides a new framework for probing and understanding mixed conduction in ion-electron coupled systems.

### [K-ion intercalation memristors in prussian blue analogs revealed by C-AFM for Non-Volatile memory and Neuromorphic Computing](http://arxiv.org/abs/2601.04724v1)
**2026-01-08** | *L. B. Avila, O. Leuve, M. Pohlitz et al.*

> Here, we demonstrate K-ion intercalation-mediated resistive switching in Prussian blue analogs (PBAs), a mechanism widely exploited in potassium batteries but not previously resolved at the nanoscale for memristive operation. Using C-AFM, we directly visualize and electrically control this intercalation process within sub-100-nm volumes, revealing reversible, localized conductance modulation driven by K-ion intercalation and Fe2+/Fe3+ redox reconfiguration. This nanoscale operability highlights the exceptional potential of PBAs for high-scalable and low-dimension memristor-based devices integration. Due to their modular composition, PBAs constitute a chemically rich, earth-abundant materials platform whose electronic and ionic properties can be precisely tuned for specific device functions. K-ion intercalation PBA-based memristor devices, with their singlestep, aqueous, and room-temperature fabrication, enable low-cost, large-scale processing compatible with CMOS, without any additional post-fabrication processing. Our findings establish PBAs as a new class of intercalation memristors with scalable nanoscale switching and exceptional materials versatility, toward highly integrated neuromorphic and non-volatile memory technologies. This work provides the first demonstration of intercalation-driven resistive switching under ultrafast voltage sweeps, with PW operating up to 200 V/s and PB up to 50 V/s. This unprecedented speed establishes PBAs as a distinct, high-rate class of K-ion intercalation memristors suitable for fast, high-density neuromorphic and memory applications.

### [Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing](http://arxiv.org/abs/2601.04476v1)
**2026-01-08** | *Chuanzhen Wang, Leo Zhang, Eric Liu*

> Recent hardware acceleration advances have enabled powerful specialized accelerators for finite element computations, spiking neural network inference, and sparse tensor operations. However, existing approaches face fundamental limitations: (1) finite element methods lack comprehensive rounding error analysis for reduced-precision implementations and use fixed precision assignment strategies that cannot adapt to varying numerical conditioning; (2) spiking neural network accelerators cannot handle non-spike operations and suffer from bit-width escalation as network depth increases; and (3) FPGA tensor accelerators optimize only for dense computations while requiring manual configuration for each sparsity pattern. To address these challenges, we introduce \textbf{Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing}, a novel framework that integrates three enhanced modules with memory-guided adaptation for efficient mixed-workload processing on unified platforms. Our approach employs memory-guided precision selection to overcome fixed precision limitations, integrates experience-driven bit-width management and dynamic parallelism adaptation for enhanced spiking neural network acceleration, and introduces curriculum learning for automatic sparsity pattern discovery. Extensive experiments on FEniCS, COMSOL, ANSYS benchmarks, MNIST, CIFAR-10, CIFAR-100, DVS-Gesture datasets, and COCO 2017 demonstrate 2.8\% improvement in numerical accuracy, 47\% throughput increase, 34\% energy reduction, and 45-65\% throughput improvement compared to specialized accelerators. Our work enables unified processing of finite element methods, spiking neural networks, and sparse computations on a single platform while eliminating data transfer overhead between separate units.

### [A Quantifiable Information-Processing Hierarchy Provides a Necessary Condition for Detecting Agency](http://arxiv.org/abs/2601.03498v1)
**2026-01-07** | *Brett J. Kagan, Valentina Baccetti, Brian D. Earp et al.*

> As intelligent systems are developed across diverse substrates - from machine learning models and neuromorphic hardware to in vitro neural cultures - understanding what gives a system agency has become increasingly important. Existing definitions, however, tend to rely on top-down descriptions that are difficult to quantify. We propose a bottom-up framework grounded in a system's information-processing order: the extent to which its transformation of input evolves over time. We identify three orders of information processing. Class I systems are reactive and memoryless, mapping inputs directly to outputs. Class II systems incorporate internal states that provide memory but follow fixed transformation rules. Class III systems are adaptive; their transformation rules themselves change as a function of prior activity. While not sufficient on their own, these dynamics represent necessary informational conditions for genuine agency. This hierarchy offers a measurable, substrate-independent way to identify the informational precursors of agency. We illustrate the framework with neurophysiological and computational examples, including thermostats and receptor-like memristors, and discuss its implications for the ethical and functional evaluation of systems that may exhibit agency.

### [Integrated magnonic chip using cascaded logic](http://arxiv.org/abs/2601.02644v1)
**2026-01-06** | *Mengying Guo, Xudong Jing, KristÃ½na DavÃ­dkovÃ¡ et al.*

> The transistor transformed not only electronics but everyday life, and the integrated circuit - now simply the "chip" - made computation scalable and ubiquitous. Magnonics has long promised a parallel path to low-energy information processing by using spin waves instead of charge. Progress, however, has been limited by two fundamental obstacles: intrinsic attenuation of spin waves and the requirement for precisely normalised output intensity and input phase to ensure reliable logic operation - conditions that are difficult to maintain in large-scale circuits owing to inevitable imperfections. Here, we report an integrated magnonic circuit that overcomes both limitations through engineered nonlinearity in nanoscale yttrium iron garnet waveguides. Nonlinear self-adjustment of the spin wave phase renders logic operation insensitive to the relative phases of the inputs, while a deeply nonlinear, threshold-activated self-normalised excitation restores and standardises the output intensity. Using space-resolved micro-focused Brillouin light scattering, we demonstrate reconfigurable AND, OR and three-input majority gates and realise deterministic cascading across sequential stages, establishing a scalable on-chip logic primitive. The architecture operates with gigahertz frequencies, supports dynamic threshold control for functional reconfiguration, and is compatible with scalable integration, making it attractive for adaptive and neuromorphic computing. By resolving phase-independent operation and signal restoration at the level of device physics, this work advances magnonics from isolated proof-of-concept devices towards integrated magnonic chips that can complement advanced CMOS in energy-constrained computing tasks.

### [Sparsity-Aware Streaming SNN Accelerator with Output-Channel Dataflow for Automatic Modulation Classification](http://arxiv.org/abs/2601.02613v1)
**2026-01-06** | *Kuilian Yang, Li Zhang, Ahmed M. Eltawil et al.*

> The rapid advancement of wireless communication technologies, including 5G, emerging 6G networks, and the large-scale deployment of the Internet of Things (IoT), has intensified the need for efficient spectrum utilization. Automatic modulation classification (AMC) plays a vital role in cognitive radio systems by enabling real-time identification of modulation schemes for dynamic spectrum access and interference mitigation. While deep neural networks (DNNs) offer high classification accuracy, their computational and energy demands pose challenges for real-time edge deployment. Spiking neural networks (SNNs), with their event-driven nature, offer inherent energy efficiency, but achieving both high throughput and low power under constrained hardware resources remains challenging. This work proposes a sparsity-aware SNN streaming accelerator optimized for AMC tasks. Unlike traditional systolic arrays that exploit sparsity but suffer from low throughput, or streaming architectures that achieve high throughput but cannot fully utilize input and weight sparsity, our design integrates both advantages. By leveraging the fixed nature of kernels during inference, we apply the gated one-to-all product (GOAP) algorithm to compute only on non-zero input-weight intersections. Extra or empty iterations are precomputed and embedded into the inference dataflow, eliminating dynamic data fetches and enabling fully pipelined, control-free inter-layer execution. Implemented on an FPGA, our sparsity-aware output-channel dataflow streaming (SAOCDS) accelerator achieves 23.5 MS/s (approximately double the baseline throughput) on the RadioML 2016 dataset, while reducing dynamic power and maintaining comparable classification accuracy. These results demonstrate strong potential for real-time, low-power deployment in edge cognitive radio systems.

### [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](http://arxiv.org/abs/2601.02253v1)
**2026-01-05** | *Emrah Mete, Emin Erkan Korkmaz*

> The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

---

## ðŸ§  Algorithms & Theory

### [Supervised Spike Agreement Dependent Plasticity for Fast Local Learning in Spiking Neural Networks](http://arxiv.org/abs/2601.08526v1)
**2026-01-13** | *Gouri Lakshmi S, Athira Chandrasekharan, Harshit Kumar et al.*

> Spike-Timing-Dependent Plasticity (STDP) provides a biologically grounded learning rule for spiking neural networks (SNNs), but its reliance on precise spike timing and pairwise updates limits fast learning of weights. We introduce a supervised extension of Spike Agreement-Dependent Plasticity (SADP), which replaces pairwise spike-timing comparisons with population-level agreement metrics such as Cohen's kappa. The proposed learning rule preserves strict synaptic locality, admits linear-time complexity, and enables efficient supervised learning without backpropagation, surrogate gradients, or teacher forcing.   We integrate supervised SADP within hybrid CNN-SNN architectures, where convolutional encoders provide compact feature representations that are converted into Poisson spike trains for agreement-driven learning in the SNN. Extensive experiments on MNIST, Fashion-MNIST, CIFAR-10, and biomedical image classification tasks demonstrate competitive performance and fast convergence. Additional analyses show stable performance across broad hyperparameter ranges and compatibility with device-inspired synaptic update dynamics. Together, these results establish supervised SADP as a scalable, biologically grounded, and hardware-aligned learning paradigm for spiking neural networks.

### [Sleep-Based Homeostatic Regularization for Stabilizing Spike-Timing-Dependent Plasticity in Recurrent Spiking Neural Networks](http://arxiv.org/abs/2601.08447v1)
**2026-01-13** | *Andreas Massey, Aliaksandr Hubin, Stefano Nichele et al.*

> Spike-timing-dependent plasticity (STDP) provides a biologically-plausible learning mechanism for spiking neural networks (SNNs); however, Hebbian weight updates in architectures with recurrent connections suffer from pathological weight dynamics: unbounded growth, catastrophic forgetting, and loss of representational diversity. We propose a neuromorphic regularization scheme inspired by the synaptic homeostasis hypothesis: periodic offline phases during which external inputs are suppressed, synaptic weights undergo stochastic decay toward a homeostatic baseline, and spontaneous activity enables memory consolidation. We demonstrate that this sleep-wake cycle prevents weight saturation while preserving learned structure. Empirically, we find that low to intermediate sleep durations (10-20\% of training) improve stability on MNIST-like benchmarks in our STDP-SNN model, without any data-specific hyperparameter tuning. In contrast, the same sleep intervention yields no measurable benefit for the surrogate-gradient spiking neural network (SG-SNN). Taken together, these results suggest that periodic, sleep-based renormalization may represent a fundamental mechanism for stabilizing local Hebbian learning in neuromorphic systems, while also indicating that special care is required when integrating such protocols with existing gradient-based optimization methods.

### [Spiking Neural-Invariant Kalman Fusion for Accurate Localization Using Low-Cost IMUs](http://arxiv.org/abs/2601.08248v1)
**2026-01-13** | *Yaohua Liu, Qiao Xu, Yemin Wang et al.*

> Low-cost inertial measurement units (IMUs) are widely utilized in mobile robot localization due to their affordability and ease of integration. However, their complex, nonlinear, and time-varying noise characteristics often lead to significant degradation in localization accuracy when applied directly for dead reckoning. To overcome this limitation, we propose a novel brain-inspired state estimation framework that combines a spiking neural network (SNN) with an invariant extended Kalman filter (InEKF). The SNN is designed to extract motion-related features from long sequences of IMU data affected by substantial random noise and is trained via a surrogate gradient descent algorithm to enable dynamic adaptation of the covariance noise parameter within the InEKF. By fusing the SNN output with raw IMU measurements, the proposed method enhances the robustness and accuracy of pose estimation. Extensive experiments conducted on the KITTI dataset and real-world data collected using a mobile robot equipped with a low-cost IMU demonstrate that the proposed approach outperforms state-of-the-art methods in localization accuracy and exhibits strong robustness to sensor noise, highlighting its potential for real-world mobile robot applications.

### [A brain-inspired information fusion method for enhancing robot GPS outages navigation](http://arxiv.org/abs/2601.08244v1)
**2026-01-13** | *Yaohua Liu, Hengjun Zhang, Binkai Ou*

> Low-cost inertial navigation systems (INS) are prone to sensor biases and measurement noise, which lead to rapid degradation of navigation accuracy during global positioning system (GPS) outages. To address this challenge and improve positioning continuity in GPS-denied environments, this paper proposes a brain-inspired GPS/INS fusion network (BGFN) based on spiking neural networks (SNNs). The BGFN architecture integrates a spiking Transformer with a spiking encoder to simultaneously extract spatial features from inertial measurement unit (IMU) signals and capture their temporal dynamics. By modeling the relationship between vehicle attitude, specific force, angular rate, and GPS-derived position increments, the network leverages both current and historical IMU data to estimate vehicle motion. The effectiveness of the proposed method is evaluated through real-world field tests and experiments on public datasets. Compared to conventional deep learning approaches, the results demonstrate that BGFN achieves higher accuracy and enhanced reliability in navigation performance, particularly under prolonged GPS outages.

### [The Potential Impact of Neuromorphic Computing on Radio Telescope Observatories](http://arxiv.org/abs/2601.07130v1)
**2026-01-12** | *Nicholas J. Pritchard, Richard Dodson, Andreas Wicenec*

> Radio astronomy relies on bespoke, experimental and innovative computing solutions. This will continue as next-generation telescopes such as the Square Kilometre Array (SKA) and next-generation Very Large Array (ngVLA) take shape. Under increasingly demanding power consumption, and increasingly challenging radio environments, science goals may become intractable with conventional von Neumann computing due to related power requirements. Neuromorphic computing offers a compelling alternative, and combined with a desire for data-driven methods, Spiking Neural Networks (SNNs) are a promising real-time power-efficient alternative. Radio Frequency Interference (RFI) detection is an attractive use-case for SNNs where recent exploration holds promise. This work presents a comprehensive analysis of the potential impact of deploying varying neuromorphic approaches across key stages in radio astronomy processing pipelines for several existing and near-term instruments. Our analysis paves a realistic path from near-term FPGA deployment of SNNs in existing instruments, allowing the addition of advanced data-driven RFI detection for no capital cost, to neuromorphic ASICs for future instruments, finding that commercially available solutions could reduce the power budget for key processing elements by up to three orders of magnitude, transforming the operational budget of the observatory. High-data-rate spectrographic processing could be a well-suited target for the neuromorphic computing industry, as we cast radio telescopes as the world's largest in-sensor compute challenge.

### [Efficient Aspect Term Extraction using Spiking Neural Network](http://arxiv.org/abs/2601.06637v1)
**2026-01-10** | *Abhishek Kumar Mishra, Arya Somasundaram, Anup Das et al.*

> Aspect Term Extraction (ATE) identifies aspect terms in review sentences, a key subtask of sentiment analysis. While most existing approaches use energy-intensive deep neural networks (DNNs) for ATE as sequence labeling, this paper proposes a more energy-efficient alternative using Spiking Neural Networks (SNNs). Using sparse activations and event-driven inferences, SNNs capture temporal dependencies between words, making them suitable for ATE. The proposed architecture, SpikeATE, employs ternary spiking neurons and direct spike training fine-tuned with pseudo-gradients. Evaluated on four benchmark SemEval datasets, SpikeATE achieves performance comparable to state-of-the-art DNNs with significantly lower energy consumption. This highlights the use of SNNs as a practical and sustainable choice for ATE tasks.

### [Nonlinear mode interactions under parametric excitation in a YIG microdisk](http://arxiv.org/abs/2601.05775v1)
**2026-01-09** | *Gabriel Soares, Rafael Lopes Seeger, Amel Kolli et al.*

> A pair of quantized spin-wave modes is driven by two-tone parallel pumping in a YIG microdisk. The nonlinear dynamics is experimentally investigated by probing the resulting steady state, which is found to critically depend on the chosen pair of modes, the detuning between the pump frequencies and the modes parametric resonance, as well as the temporal sequence of the two rf tones. A general theory of parametric excitation in confined structures based on magnetization normal modes is developed and quantitatively accounts for the observed dependence and non-commutative behaviors, which emerge from the interplay between the self and mutual nonlinear frequency shifts of the spin-wave modes. Owing to its high degree of external controllability and scalability to larger sets of modes, this dynamical system provides a model platform for exploring nonlinear phenomena and a promising route toward rf driven state mapping relevant to neuromorphic and unconventional computing.

### [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](http://arxiv.org/abs/2601.05205v1)
**2026-01-08** | *Zain Iqbal, Lorenzo Valerio*

> Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.

---

## ðŸ‘ï¸ Applications & Sensing

### [UEOF: A Benchmark Dataset for Underwater Event-Based Optical Flow](http://arxiv.org/abs/2601.10054v1)
**2026-01-15** | *Nick Truong, Pritam P. Karmokar, William J. Beksi*

> Underwater imaging is fundamentally challenging due to wavelength-dependent light attenuation, strong scattering from suspended particles, turbidity-induced blur, and non-uniform illumination. These effects impair standard cameras and make ground-truth motion nearly impossible to obtain. On the other hand, event cameras offer microsecond resolution and high dynamic range. Nonetheless, progress on investigating event cameras for underwater environments has been limited due to the lack of datasets that pair realistic underwater optics with accurate optical flow. To address this problem, we introduce the first synthetic underwater benchmark dataset for event-based optical flow derived from physically-based ray-traced RGBD sequences. Using a modern video-to-event pipeline applied to rendered underwater videos, we produce realistic event data streams with dense ground-truth flow, depth, and camera motion. Moreover, we benchmark state-of-the-art learning-based and model-based optical flow prediction methods to understand how underwater light transport affects event formation and motion estimation accuracy. Our dataset establishes a new baseline for future development and evaluation of underwater event-based perception algorithms. The source code and dataset for this project are publicly available at https://robotic-vision-lab.github.io/ueof.

### [Hybrid guided variational autoencoder for visual place recognition](http://arxiv.org/abs/2601.09248v1)
**2026-01-14** | *Ni Wang, Zihan You, Emre Neftci et al.*

> Autonomous agents such as cars, robots and drones need to precisely localize themselves in diverse environments, including in GPS-denied indoor environments. One approach for precise localization is visual place recognition (VPR), which estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of our model is based on a spiking neural network model which is compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in our new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while, showing robust performance also under various illumination conditions. When tested with novel visual inputs from unknown scenes, our model can distinguish between these places, which demonstrates a high generalization capability by learning the essential features of location. Our compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.

### [Heterogeneous computing platform for real-time robotics](http://arxiv.org/abs/2601.09755v1)
**2026-01-13** | *Jakub Fil, Yulia Sandamirskaya, Hector Gonzalez et al.*

> After Industry 4.0 has embraced tight integration between machinery (OT), software (IT), and the Internet, creating a web of sensors, data, and algorithms in service of efficient and reliable production, a new concept of Society 5.0 is emerging, in which infrastructure of a city will be instrumented to increase reliability, efficiency, and safety. Robotics will play a pivotal role in enabling this vision that is pioneered by the NEOM initiative - a smart city, co-inhabited by humans and robots. In this paper we explore the computing platform that will be required to enable this vision. We show how we can combine neuromorphic computing hardware, exemplified by the Loihi2 processor used in conjunction with event-based cameras, for sensing and real-time perception and interaction with a local AI compute cluster (GPUs) for high-level language processing, cognition, and task planning. We demonstrate the use of this hybrid computing architecture in an interactive task, in which a humanoid robot plays a musical instrument with a human. Central to our design is the efficient and seamless integration of disparate components, ensuring that the synergy between software and hardware maximizes overall performance and responsiveness. Our proposed system architecture underscores the potential of heterogeneous computing architectures in advancing robotic autonomy and interactive intelligence, pointing toward a future where such integrated systems become the norm in complex, real-time applications.

### [An Event-Based Opto-Tactile Skin](http://arxiv.org/abs/2601.03907v1)
**2026-01-07** | *Mohammadreza Koolani, Simeon Bamford, Petr Trunin et al.*

> This paper presents a neuromorphic, event-driven tactile sensing system for soft, large-area skin, based on the Dynamic Vision Sensors (DVS) integrated with a flexible silicone optical waveguide skin. Instead of repetitively scanning embedded photoreceivers, this design uses a stereo vision setup comprising two DVS cameras looking sideways through the skin. Such a design produces events as changes in brightness are detected, and estimates press positions on the 2D skin surface through triangulation, utilizing Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to find the center of mass of contact events resulting from pressing actions. The system is evaluated over a 4620 mm2 probed area of the skin using a meander raster scan. Across 95 % of the presses visible to both cameras, the press localization achieved a Root-Mean-Squared Error (RMSE) of 4.66 mm. The results highlight the potential of this approach for wide-area flexible and responsive tactile sensors in soft robotics and interactive environments. Moreover, we examined how the system performs when the amount of event data is strongly reduced. Using stochastic down-sampling, the event stream was reduced to 1/1024 of its original size. Under this extreme reduction, the average localization error increased only slightly (from 4.66 mm to 9.33 mm), and the system still produced valid press localizations for 85 % of the trials. This reduction in pass rate is expected, as some presses no longer produce enough events to form a reliable cluster for triangulation. These results show that the sensing approach remains functional even with very sparse event data, which is promising for reducing power consumption and computational load in future implementations. The system exhibits a detection latency distribution with a characteristic width of 31 ms.

---

## ðŸ“‚ General / Uncategorized

### [Annotated PIM Bibliography](http://arxiv.org/abs/2601.09002v1)
**2026-01-13** | *Peter M. Kogge*

> Processing in Memory (PIM) and similar terms such as Compute In Memory (CIM), Logic in Memory (LIM), In Memory Computing (IMC), and Near Memory Computing (NMC) have gained attention recently as a potentially ``revolutionary new'' technique. The truth, however, is that many examples of the technology go back over 60 years. This document attempts to provide an annotated bibliography of PIM technology that attempts to cover the whole time-frame, and is organized to augment a forth-coming article.

---

